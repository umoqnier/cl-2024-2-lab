# -*- coding: utf-8 -*-
"""Practica02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rDDvsD--2-xbBEGW3R_jO-AtinzTVgp8

# Práctica 2: Niveles lingüísticos II
Elaborado por: Alejandro Axel Rodríguez Sánchez  
Correo: ahexo@ciencias.unam.mx   
Github: @Ahexo  
Número de Cuenta: 315247697  
Institución: Facultad de Ciencias UNAM  
Asignatura: Lingüística computacional  
Semestre: 2024-2  
Grupo: 7014

# Implementando un POS de otomí con CRFs

Vamos a emplear sklearn para constuir el CRF, numpy para algunas de las operaciones de medición, unidecode para el tratamiento de etiquetas que no son ASCII y tabulate para desplegar resultados.
"""

import numpy as np
import random
from unidecode import unidecode

from sklearn_crfsuite import CRF
from sklearn.model_selection import train_test_split

from sklearn.metrics import *
from json import loads

from tabulate import tabulate

"""## Definimos un conjunto de características

El otomí tiene algunas características morfosintácticas de las que nos podemos valer para construir un buen conjunto de características utiles para nuestro CRF:

* Es una lengua tonal y por lo general tiene tres todos distintos: alto, bajo y ascendente. Los dos primeros se encuentran denotados por un acento o una doble vocal respectivamente.
* Los pronominales suelen iniciar con «nu» o «gigo».
* Las glotales se emplean frecuentemente en el otomí, y se introducen textualmente con una apostrofe. Se pueden usar para identificar donde se componen dos palabras.
* Las negaciones inician con el prefijo «hín».

Para tratar los casos donde hay caracteres en codificación UTF-8, vamos a emplear la biblioteca de Python [unidecode](https://pypi.org/project/Unidecode/), la cual «normaliza» textos que no están en ASCII en este mismo de la forma mas legible y parecida al texto original que se pueda.
"""

def tono(palabra):
    # Ascendente
    for vocal in ["aa","ee","ii","oo","uu"]:
        if vocal in palabra:
            return 1

    # Alto
    for vocal in ["á","é","í","ó","ú"]:
        if vocal in palabra:
            return 2
    # Bajo
    return 3

def pos_letra(segmento,palabra):
    try:
        return palabra.index(segmento)
    except:
        return -1

def encontrar_features(palabra, pos):
    features = {
        'bias': 1.0,
        'len': len(palabra),
        'pos': pos,
        'tono': tono(palabra),

        'glotal': pos_letra("'", palabra),
        'o_pos': pos_letra("o", palabra),
        'm_pos': pos_letra("m", palabra),
        'n_pos': pos_letra("n", palabra),
        'neg': pos_letra("hín", palabra),
        'bi': pos_letra("bi", palabra),

        'unicode_palabra': unidecode(palabra),
        'utf-8': palabra.encode(encoding = 'UTF-8')
    }
    return features

"""Esta es una función auxiliar para generar el reporte de métricas mas adelante."""

def report(true, predictions):
    report = classification_report(y_true=true, y_pred=predictions, zero_division=np.nan)
    print(report)
    print("Accuracy:", accuracy_score(true, predictions))
    print("Precision:", precision_score(true, predictions, average="macro", zero_division=np.nan))
    print("Recall:", recall_score(true, predictions, average="macro", zero_division=np.nan))
    print("f1:", f1_score(true, predictions, average="macro"))

"""## Importando y cargando corpus en una estructura de datos"""

corpus = []
with open("corpus-otomi.txt") as raw_corpus:
    for line in raw_corpus:
        line = loads(line)
        sentence = []
        for idx, segmento_palabra in enumerate(line):
            palabra = "".join([part[0].strip() for part in segmento_palabra[0:-1]])
            sentence.append([segmento_palabra[-1].strip(),encontrar_features(palabra, idx)])
        corpus.append(sentence)

# Arreglo de features
X = [[palabra[1] for palabra in sentence] for sentence in corpus]
# Arreglo de etiquetas
y = [[palabra[0] for palabra in sentence] for sentence in corpus]

"""## Dividimos el corpus en un set de entrenamiento y uno de pruebas"""

seed = random.randint(39, 100)
np.random.seed(seed)
random.seed(seed)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)

"""## Entrenamos un CRF"""

crf = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=1000, all_possible_transitions=True, verbose=True)
try:
    crf.fit(X_train, y_train)
except AttributeError as e:
    print(e)
y_pred = crf.predict(X_test)

"""## Obtenemos resultados
Finalmente, calculamos las métricas deseadas (Accuracy, Precision, Recall y F1) con sklearn, así como una muestra de preddiciones para comparar resultados entre las predicciones del modelo y el set de pruebas.
"""

y_test_flat = [label for sent_labels in y_test for label in sent_labels]
y_pred_flat = [label for sent_labels in y_pred for label in sent_labels]

report(y_test_flat, y_pred_flat)

"""## Finalmente, generamos una tabla comparando valores originales y predicciones del modelo"""

headers = ["Palabra", "Original", "Predicción"]
table_data = []
for idx, x in enumerate(X_test[seed]):
  table_data.append([x['utf-8'].decode(encoding='UTF-8'), y_test[seed][idx], y_pred[seed][idx]])

print(f"\nCOMPARATIVO DE PREDICCIONES DEL MODELO:")
print(tabulate(table_data, headers=headers, tablefmt="simple"))