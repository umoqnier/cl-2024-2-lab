# -*- coding: utf-8 -*-
"""practica01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1B1dsEBW5rZqXsmotVrlj-v5UM2dG8QTd

# Práctica 1: Niveles lingüísticos I
Elaborado por: Alejandro Axel Rodríguez Sánchez  
Correo: ahexo@ciencias.unam.mx   
Github: @Ahexo  
Número de Cuenta: 315247697  
Institución: Facultad de Ciencias UNAM  
Asignatura: Lingüística computacional  
Semestre: 2024-2  
Grupo: 7014  

---

## Especificación de la práctica

1. Agregar un nuevo modo de búsqueda donde se extienda el comportamiento básico del buscador para ahora buscar por frases.

```
[es_MX]>>> Hola que hace
 /ola/ /ke/ /ase/
```


2. Agregar un modo de búsqueda donde dada una palabra te muestre sus *homofonos*[1]. Debe mostrar su representación IPA y la lista de homofonos (si existen)

```
[es_MX]>>> habares
/aβaɾes/
['abares', 'habares', 'havares']
```

[1]: palabras con el mismo sonido pero distinta ortografía

3. Observe las distribuciones de longitud de palabra y de número de morfemas por palabra para todas lenguas. Basado en esos datos, haga un comentario sobre las diferencias en morfología de las lenguas

**EXTRA**: Mejorar la solución en el escenario cuando no se encuentran las palabras en el dataset (incisos 1. y 2.) mostrando palabras similares. Ejemplo:

```
[es_MX]>> pero
No se encontro <<pero>> en el dataset. Palabras aproximadas:
perro /pero/
perno /peɾno/
[es_MX]>>
```
---

## Obteniendo el corpus
"""

lang_codes = {
  "ar": "Arabic (Modern Standard)",
  "de": "German",
  "en_UK": "English (Received Pronunciation)",
  "en_US": "English (General American)",
  "eo": "Esperanto",
  "es_ES": "Spanish (Spain)",
  "es_MX": "Spanish (Mexico)",
  "fa": "Persian",
  "fi": "Finnish",
  "fr_FR": "French (France)",
  "fr_QC": "French (Québec)",
  "is": "Icelandic",
  "ja": "Japanese",
  "jam": "Jamaican Creole",
  "km": "Khmer",
  "ko": "Korean",
  "ma": "Malay (Malaysian and Indonesian)",
  "nb": "Norwegian Bokmål",
  "nl": "Dutch",
  "or": "Odia",
  "ro": "Romanian",
  "sv": "Swedish",
  "sw": "Swahili",
  "tts": "Isan",
  "vi_C": "Vietnamese (Central)",
  "vi_N": "Vietnamese (Northern)",
  "vi_S": "Vietnamese (Southern)",
  "yue": "Cantonese",
  "zh": "Mandarin"
}
iso_lang_codes = list(lang_codes.keys())

"""# Definiendo funciones elementales para operar los datasets y su contenido
Estas vienen copiadas de la especificación de la práctica, con ligeras modificaciones.
"""

def response_to_dict(ipa_list: list) -> dict:
    """Parse to dict the list of word-IPA

    Each element of text has the format:
    [WORD][TAB][IPA]

    Parameters
    ----------
    ipa_list: list
        List with each row of ipa-dict raw dataset file

    Returns
    -------
    dict:
        A dictionary with the word as key and the phonetic
        representation as value
    """
    result = {}
    for item in ipa_list:
        item_list = item.split("\t")
        result[item_list[0]] = item_list[1]
    return result

import requests as r

def get_ipa_dict(iso_lang: str) -> dict:
    """Get ipa-dict file from Github

    Parameters:
    -----------
    iso_lang:
        Language as iso code

    Results:
    --------
    dict:
        Dictionary with words as keys and phonetic representation
        as values for a given lang code
    """
    response = r.get(f"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/{iso_lang}.txt")
    raw_data = response.text.split("\n")
    return response_to_dict(raw_data[:-1])

def get_ipa_transcriptions(word: str, dataset: dict) -> list[str]:
    """Search for word in a given dataset of IPA phonetics

    Given a word this function return the IPA transcriptions

    Parameters:
    -----------
    word: str
        A word to search in the dataset
    dataset: dict
        A dataset for a given language code
    Returns
    -------
    list:
        A list with all the found IPA transcriptions of the input word.
    """
    return dataset.get(word.lower(), "NOT FOUND").split(", ")

# El dataset comenzará vacío y se descargaran los corpus sobre demanda.
dataset = {}

"""# Mas funciones auxiliares
Estas si estan completamente introducidas por un servidor
"""

def levenshtein(s1: str, s2: str) -> int:
    """Calcula la distancia de Levenshtein entre dos cadenas, es decir
    cuantas modificaciones o adiciones de caracteres hay que efectuar
    para transformar una en otra.

    Parameters
    ----------
    s1: str
        Primer cadena a evaluar.

    s2: str
        Segunda cadena a evaluar.

    Returns
    -------
    int:
        La distancia de Levenshtein entre las dos palabras.
    """
    if len(s1) < len(s2):
        return levenshtein(s2, s1)

    # If one of the strings is empty
    if len(s2) == 0:
        return len(s1)

    # Initialize the distance matrix
    previous_row = range(len(s2) + 1)
    for i, c1 in enumerate(s1):
        current_row = [i + 1]
        for j, c2 in enumerate(s2):
            insertions = previous_row[j + 1] + 1
            deletions = current_row[j] + 1
            substitutions = previous_row[j] + (c1 != c2)
            current_row.append(min(insertions, deletions, substitutions))
        previous_row = current_row

    return previous_row[-1]

def buscar_desconocida(palabra_desconocida: str, dataset: dict):
  """Buscamos las palabras similares en un dataset a una palabra desconocida dada.
    Esto lo hacemos limitandonos a buscar palabras de misma longitud y distancia de
    Levenshtein igual o menor a 2. Al final las imprimimos en pantalla para que
    el usuario las pueda comparar.

    Parameters
    ----------
    palabra_desconocida: str
        Cadena que sabemos que no se encuentra en el dataset.

    dataset: dict
        Dataset sobre el cual buscar.
    """
  print(f"No se encontró <<{palabra_desconocida}>> en el dataset, se muestran algunas palabras similares:")

  coincidencias_encontradas = 0

  for ejemplar in dataset.keys():
      if len(ejemplar) is len(palabra_desconocida):
        distancia = levenshtein(ejemplar, palabra_desconocida)
        if distancia < 2:
          print(f"{ejemplar}: {get_ipa_transcriptions(ejemplar, dataset)}")
          coincidencias_encontradas += 1

  if coincidencias_encontradas < 1:
    print("No se hallaron coincidencias :(")

def buscar_desconocidas(palabras_desconocidas: list, dataset: dict):
  """Buscamos las palabras similares en un dataset para un conjunto de palabras
    desconocidas.
    Parameters
    ----------
    palabra_desconocidas: list
        Palabras que sabemos que no se encuentran en el dataset.

    dataset: dict
        Dataset sobre el cual buscar.
    """
  for palabra in palabras_desconocidas:
    buscar_desconocida(palabra, dataset)

"""# Definiendo el ciclo de ejecución"""

print(f"Lenguas disponibles: {(iso_lang_codes)}")
print("Deja la casilla en blanco y presiona enter para salir.")

lang = "none"

while lang:
  lang = input("lang>> ")
  if lang in iso_lang_codes:

    if lang not in dataset:
      print("Corpus no encontrado. Descargando...")
      dataset.update({lang : get_ipa_dict(lang)})

    sub_dataset = dataset[lang]

    print("Ingresa 1 para buscar homofonos, cualquier otra cosa para buscar transcripciones IPA:")
    mode = input("modo>>")

    # Buscar homofonos

    query = "none"

    if mode == "1":

      while query:
        query = input(f"[{lang}][Homofonos]>> ")

        if query == "":
          break

        # Solo vamos a buscar la primera palabra del input del usuario
        palabra_a_buscar = query.split()[0]
        transcripcion_original = get_ipa_transcriptions(palabra_a_buscar, sub_dataset)

        if transcripcion_original[0] == "NOT FOUND":
            buscar_desconocida(palabra_a_buscar, sub_dataset)
        else:
          homofonos = []
          for ejemplar in sub_dataset.keys():
            if sub_dataset[ejemplar] in transcripcion_original:
              homofonos.append(ejemplar)
          print(f"Se buscó: {palabra_a_buscar}\n{transcripcion_original}\nHomofonos hallados: {homofonos}")

    else:
      # Buscar transcripciones IPA

      while query:
        query = input(f"[{lang}][Transcripciones]>> ")

        resultado_final = []
        desconocidas = []
        num_desconocidas = 0
        for palabra in query.split():
          resultado = get_ipa_transcriptions(palabra, sub_dataset)

          if resultado[0] != "NOT FOUND":
            resultado_final += resultado
          else:
            desconocidas.append(palabra)
            resultado_final += f"/{palabra}[!]/"

          resultado_final += [" "]

        print("".join(resultado_final))
        buscar_desconocidas(desconocidas, sub_dataset)

  elif lang:
    print("Ese lenguaje no está disponible, intenta con otro:")

print("Adios :)")