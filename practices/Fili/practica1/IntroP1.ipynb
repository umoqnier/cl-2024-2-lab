{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f47c3c-dfb4-49ee-907f-84d002ac892c",
   "metadata": {},
   "source": [
    "## Practica 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c2309b-8ae8-4c79-8ab7-6b7009fdecf6",
   "metadata": {},
   "source": [
    "### Fonologia\n",
    "- La fonolog√≠a es una rama de la Ling√º√≠stica que estudia como las lenguajes sistematicamente organizan los fonemas\n",
    "- Estudia como los humanos producimos y percibimos el lenguaje\n",
    "    - Producci√≥n: La forma en que producimos el lenguaje\n",
    "    - Percepci√≥n: La forma en que interpretamos el lenguaje\n",
    "\n",
    "### Fonetica\n",
    "El estudio de los sonidos f√≠sicos del discurso humano. Es la rama de la ling√º√≠stica que estudia la producci√≥n y percepci√≥n de los sonidos de una lengua con respecto a sus manifestaciones f√≠sicas.\n",
    "\n",
    "**International Phonetic Alphabet (IPA)**\n",
    "\n",
    "- Las lenguas naturales tienen muchos sonidos diferentes por lo que necesitamos una forma de describirlos independientemente de las lenguas\n",
    "- Por ejemplo: Los sonidos del habla se determinan por los movimientos de la boca necesarios para producirlos\n",
    "- Las dos grandes categor√≠as: Consonantes y Vocales\n",
    "- IPA es una representaci√≥n escrita de los sonidos del habla\n",
    "\n",
    "**Dataset: IPA**\n",
    "Diccionario de palabras para varios idiomas con su representacion fonetica.\n",
    "Representacion simple, una palabra por renglon con el formato:\n",
    "\n",
    "Ejemplos: \n",
    "\n",
    "mariguana     /ma…æi…£wana/  \n",
    "zyuganov's    /Ààzju…°…ën…ëvz/, /Ààzu…°…ën…ëvz/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8b73e0-4c76-4a6b-b3dd-07cce0a16e60",
   "metadata": {},
   "source": [
    "### Explorando el Corpus\n",
    "Este c√≥digo est√° dise√±ado para trabajar con un corpus de datos que contiene palabras en un\n",
    "idioma espec√≠fico junto con sus transcripciones fon√©ticas en el Alfabeto Fon√©tico Internacional (AFI). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91838861-3e17-49c7-a1d2-8ae0495add5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'bout\\t/Ààba ät/\\n'cause\\t/k…ôz/\\n'course\\t/Ààk…î…πs/\\n'cuse\\t/Ààkjuz/\\n'em\\t/…ôm/\\n'frisco\\t/Ààf…π…™sko ä/\\n'gain\\t/Àà…°…õn/\\n'k\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explorando el corpus\n",
    "import requests as r\n",
    "\n",
    "response = r.get(\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/en_US.txt\")\n",
    "response.text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "801582f3-b9df-46e4-821a-c287b85eccc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'bout\\t/Ààba ät/\",\n",
      " \"'cause\\t/k…ôz/\",\n",
      " \"'course\\t/Ààk…î…πs/\",\n",
      " \"'cuse\\t/Ààkjuz/\",\n",
      " \"'em\\t/…ôm/\",\n",
      " \"'frisco\\t/Ààf…π…™sko ä/\",\n",
      " \"'gain\\t/Àà…°…õn/\",\n",
      " \"'kay\\t/Ààke…™/\",\n",
      " \"'m\\t/…ôm/\",\n",
      " \"'n\\t/…ôn/\",\n",
      " \"'round\\t/Àà…πa änd/\",\n",
      " \"'s\\t/Àà…õs/\",\n",
      " \"'til\\t/Ààt…™…´/\",\n",
      " \"'tis\\t/Ààt…™z/\",\n",
      " \"'twas\\t/Ààtw…ôz/\",\n",
      " 'a\\t/Ààe…™/, /…ô/',\n",
      " 'a.\\t/Ààe…™/',\n",
      " \"a.'s\\t/Ààe…™z/\",\n",
      " 'a.d.\\t/Àåe…™Ààdi/',\n",
      " 'a.m.\\t/Àåe…™Àà…õm/',\n",
      " 'a.s\\t/Ààe…™z/',\n",
      " \"a's\\t/Ààe…™z/\",\n",
      " 'aaa\\t/Àåt…π…™p…ôÀà…´e…™/',\n",
      " 'aaberg\\t/Àà…ëb…ù…°/',\n",
      " 'aachen\\t/Àà…ëk…ôn/',\n",
      " 'aachener\\t/Àà…ëk…ôn…ù/',\n",
      " 'aaker\\t/Àà…ëk…ù/',\n",
      " 'aaliyah\\t/Àå…ëÀà…´iÀå…ë/',\n",
      " 'aalseth\\t/Àà…ë…´s…õŒ∏/',\n",
      " 'aamodt\\t/Àà…ëm…ôt/',\n",
      " 'aancor\\t/Àà…ënÀåk…î…π/',\n",
      " 'aardema\\t/…ë…πÀàd…õm…ô/',\n",
      " 'aardvark\\t/Àà…ë…πdÀåv…ë…πk/',\n",
      " 'aardvarks\\t/Àà…ë…πdÀåv…ë…πks/',\n",
      " 'aargh\\t/Àà…ë…π…°/',\n",
      " 'aarhus\\t/Àå…ëÀàhus/',\n",
      " 'aaron\\t/Àà…õ…π…ôn/',\n",
      " \"aaron's\\t/Àà…õ…π…ônz/\",\n",
      " 'aarons\\t/Àà…õ…π…ônz/',\n",
      " 'aaronson\\t/Àà…ë…π…ôns…ôn/, /Àà…õ…π…ôns…ôn/',\n",
      " \"aaronson's\\t/Àà…ë…π…ôns…ônz/, /Àà…õ…π…ôns…ônz/\",\n",
      " 'aarti\\t/Àà…ë…πÀåti/',\n",
      " 'aase\\t/Àà…ës/',\n",
      " 'aasen\\t/Àà…ës…ôn/',\n",
      " 'ab\\t/Àà√¶b/, /Ààe…™Ààbi/',\n",
      " 'aba\\t/Àåe…™ÀåbiÀàe…™/',\n",
      " 'ababa\\t/Àà…ëb…ôb…ô/, /…ôÀàb…ëb…ô/',\n",
      " 'abacha\\t/Àà√¶b…ôk…ô/',\n",
      " 'aback\\t/…ôÀàb√¶k/',\n",
      " 'abaco\\t/Àà√¶b…ôÀåko ä/',\n",
      " 'abacus\\t/Àà√¶b…ôk…ôs/',\n",
      " 'abad\\t/…ôÀàb…ëd/',\n",
      " 'abadaka\\t/…ôÀàb√¶d…ôk…ô/',\n",
      " 'abadi\\t/…ôÀàb√¶di/',\n",
      " 'abadie\\t/…ôÀàb√¶di/',\n",
      " 'abair\\t/…ôÀàb…õ…π/',\n",
      " 'abalkin\\t/…ôÀàb…ë…´k…™n/',\n",
      " 'abalone\\t/Àå√¶b…ôÀà…´o äni/',\n",
      " 'abalones\\t/Àå√¶b…ôÀà…´o äniz/',\n",
      " 'abalos\\t/…ëÀàb…ë…´o äz/',\n",
      " 'abandon\\t/…ôÀàb√¶nd…ôn/',\n",
      " 'abandoned\\t/…ôÀàb√¶nd…ônd/',\n",
      " 'abandoning\\t/…ôÀàb√¶nd…ôn…™≈ã/',\n",
      " 'abandonment\\t/…ôÀàb√¶nd…ônm…ônt/',\n",
      " 'abandonments\\t/…ôÀàb√¶nd…ônm…ônts/',\n",
      " 'abandons\\t/…ôÀàb√¶nd…ônz/',\n",
      " 'abanto\\t/…ôÀàb√¶nto ä/',\n",
      " 'abarca\\t/…ôÀàb…ë…πk…ô/',\n",
      " 'abare\\t/…ëÀàb…ë…πi/',\n",
      " 'abascal\\t/Àà√¶b…ôsk…ô…´/',\n",
      " 'abash\\t/…ôÀàb√¶ É/',\n",
      " 'abashed\\t/…ôÀàb√¶ Ét/',\n",
      " 'abasia\\t/…ôÀàbe…™ íj…ô/',\n",
      " 'abate\\t/…ôÀàbe…™t/',\n",
      " 'abated\\t/…ôÀàbe…™t…™d/',\n",
      " 'abatement\\t/…ôÀàbe…™tm…ônt/',\n",
      " 'abatements\\t/…ôÀàbe…™tm…ônts/',\n",
      " 'abates\\t/…ôÀàbe…™ts/',\n",
      " 'abating\\t/…ôÀàbe…™t…™≈ã/',\n",
      " 'abattoir\\t/Àå√¶b…ôtÀàw…ë…π/',\n",
      " 'abba\\t/Àà√¶b…ô/',\n",
      " 'abbado\\t/…ôÀàb…ëdo ä/',\n",
      " 'abbas\\t/…ôÀàb…ës/',\n",
      " 'abbasi\\t/…ëÀàb…ësi/',\n",
      " 'abbate\\t/Àà…ëbe…™t/',\n",
      " 'abbatiello\\t/…ëb…ëtiÀà…õ…´o ä/',\n",
      " 'abbe\\t/Àà√¶bi/, /√¶Ààbe…™/',\n",
      " 'abbenhaus\\t/Àà√¶b…ônÀåha äs/',\n",
      " 'abbett\\t/…ôÀàb…õt/',\n",
      " 'abbeville\\t/Àà√¶bv…™…´/',\n",
      " 'abbey\\t/Àà√¶bi/',\n",
      " \"abbey's\\t/Àà√¶biz/\",\n",
      " 'abbie\\t/Àà√¶bi/',\n",
      " 'abbitt\\t/Àà√¶b…™t/',\n",
      " 'abbot\\t/Àà√¶b…ôt/',\n",
      " 'abbotstown\\t/Àà√¶b…ôtÀàsta än/',\n",
      " 'abbott\\t/Àà√¶b…ôt/',\n",
      " \"abbott's\\t/Àà√¶b…ôts/\",\n",
      " 'abbottstown\\t/Àà√¶b…ôtÀàsta än/',\n",
      " 'abboud\\t/…ôÀàba äd/, /…ôÀàbud/']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint as pp\n",
    "ipa_data = response.text.split(\"\\n\")\n",
    "#print(ipa_data[-4:])\n",
    "ipa_data[-1]\n",
    "pp(ipa_data[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398df01-d382-4f83-b752-9028366f76b3",
   "metadata": {},
   "source": [
    "-  Se importa la biblioteca requests con el alias r para realizar solicitudes HTTP.\n",
    "-  Se importa la funci√≥n pprint de la biblioteca pprint con el alias pp para imprimir datos de forma m√°s legible.\n",
    "-  Se utiliza requests.get() para obtener los datos del corpus desde una URL espec√≠fica.\n",
    "-  Se divide el texto en l√≠neas utilizando split(\"\\n\"), lo que crea una lista llamada ipa_data, donde cada elemento es una l√≠nea del archivo.\n",
    "    \n",
    "*Nota:* response.text contiene el contenido del archivo obtenido.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f4584f-521e-4cd7-b98f-01f513c96bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"zyuganov's\", '/Ààzju…°…ën…ëvz/, /Ààzu…°…ën…ëvz/']\n",
      "abs --> ['/Àà√¶bz/', '/Ààe…™ÀàbiÀà…õs/']\n",
      "absolve --> ['/√¶bÀàz…ë…´v/', '/…ôbÀàz…ë…´v/']\n",
      "absolved --> ['/√¶bÀàz…ë…´vd/', '/…ôbÀàz…ë…´vd/']\n",
      "absolves --> ['/√¶bÀàz…ë…´vz/', '/…ôbÀàz…ë…´vz/']\n",
      "absolving --> ['/√¶bÀàz…ë…´v…™≈ã/', '/…ôbÀàz…ë…´v…™≈ã/']\n",
      "absorption --> ['/…ôbÀàs…î…πp É…ôn/', '/…ôbÀàz…î…πp É…ôn/']\n",
      "abstain --> ['/√¶bÀàste…™n/', '/…ôbÀàste…™n/']\n",
      "abstained --> ['/√¶bÀàste…™nd/', '/…ôbÀàste…™nd/']\n",
      "abstaining --> ['/√¶bÀàste…™n…™≈ã/', '/…ôbÀàste…™n…™≈ã/']\n",
      "abstention --> ['/√¶bÀàst…õnt É…ôn/', '/…ôbÀàst…õnt É…ôn/']\n",
      "abstentions --> ['/√¶bÀàst…õnt É…ônz/', '/…ôbÀàst…õnt É…ônz/']\n",
      "abstract --> ['/Àà√¶bÀåst…π√¶kt/', '/√¶bÀàst…π√¶kt/']\n",
      "abt --> ['/Àà√¶bt/', '/Ààe…™ÀàbiÀàti/']\n",
      "abts --> ['/Àà√¶bts/', '/Ààe…™ÀàbiÀàtiÀà…õs/', '/Ààe…™ÀàbiÀàtiz/']\n",
      "abuse --> ['/…ôbÀàjus/', '/…ôbÀàjuz/']\n",
      "abuses --> ['/…ôbÀàjus…™z/', '/…ôbÀàjuz…™z/']\n",
      "abzug --> ['/Àà√¶bÀåz…ô…°/', '/Àà√¶bÀåz ä…°/']\n",
      "academicians --> ['/Àå√¶k…ôd…ôÀàm…™ É…ônz/', '/…ôÀåk√¶d…ôÀàm…™ É…ônz/']\n",
      "accent --> ['/Àà√¶kÀås…õnt/', '/…ôkÀàs…õnt/']\n",
      "accept --> ['/√¶kÀàs…õpt/', '/…ôkÀàs…õpt/']\n",
      "acceptable --> ['/√¶kÀàs…õpt…ôb…ô…´/', '/…ôkÀàs…õpt…ôb…ô…´/']\n",
      "acceptably --> ['/√¶kÀàs…õpt…ôb…´i/', '/…ôkÀàs…õpt…ôb…´i/']\n",
      "acceptance --> ['/√¶kÀàs…õpt…ôns/', '/…ôkÀàs…õpt…ôns/']\n",
      "accepted --> ['/√¶kÀàs…õpt…™d/', '/…ôkÀàs…õpt…™d/']\n",
      "accepting --> ['/√¶kÀàs…õpt…™≈ã/', '/…ôkÀàs…õpt…™≈ã/']\n",
      "accidental --> ['/Àå√¶ks…ôÀàd…õn…ô…´/', '/Àå√¶ks…ôÀàd…õnt…ô…´/']\n",
      "accidentally --> ['/Àå√¶ks…ôÀàd…õn…ô…´i/', '/Àå√¶ks…ôÀàd…õnt…ô…´i/']\n"
     ]
    }
   ],
   "source": [
    "# Puede haber mas de una transcipcion asociada a una palabra\n",
    "print(ipa_data[-3].split(\"\\t\"))\n",
    "for data in ipa_data[300:350]:\n",
    "    word, ipa = data.split('\\t')\n",
    "    representations = ipa.split(\", \")\n",
    "    if len(representations) >= 2:\n",
    "        print(f\"{word} --> {representations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb0f57e-7c72-4346-bbdc-c6a426b578a9",
   "metadata": {},
   "source": [
    "- Itera sobre un rango espec√≠fico de l√≠neas del corpus (l√≠neas 300 a 499).\n",
    "- Para cada l√≠nea, divide la l√≠nea en dos partes usando \\t (tabulaci√≥n) como separador. La primera parte es la palabra en ingl√©s y la segunda es su transcripci√≥n fon√©tica en AFI.\n",
    "- Divide la transcripci√≥n fon√©tica en AFI en una lista de representaciones fon√©ticas individuales utilizando split(\", \").\n",
    "- Si hay dos o m√°s representaciones fon√©ticas para una palabra, imprime la palabra junto con todas sus representaciones fon√©ticas.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2772ec5-22db-4681-a600-5fb49ef8cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_to_dict(ipa_list: list) -> dict:\n",
    "    \"\"\"Parse to dict the list of word-IPA\n",
    "\n",
    "    Each element of text have the format:\n",
    "    [WORD][TAB][IPA]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ipa_list: list\n",
    "        List with each row of ipa-dict raw dataset file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict:\n",
    "        A dictionary with the word as key and the phonetic\n",
    "        representation as value\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    for item in ipa_list:\n",
    "       item_list = item.split(\"\\t\")\n",
    "       result[item_list[0]] = item_list[1]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f5af324-18c0-44af-bfbd-e6150eeaff0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/k…ôz/'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_to_dict(ipa_data[:100])[\"'cause\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7355ff-ee54-486b-bf2a-5c4098490487",
   "metadata": {},
   "source": [
    "```response_to_dict(ipa_list: list) -> dict:```\n",
    "Esta funci√≥n toma una lista de l√≠neas de texto que representan las palabras y sus transcripciones \n",
    "fon√©ticas en el formato [PALABRA][TAB][IPA] y devuelve un diccionario donde las palabras \n",
    "son las claves y las transcripciones fon√©ticas son los valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25585bdb-17f9-4b95-b2d2-663208387037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ipa_dict(iso_lang: str) -> dict:\n",
    "    \"\"\"Get ipa-dict file from Github\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    iso_lang:\n",
    "        Language as iso code\n",
    "\n",
    "    Results:\n",
    "    --------\n",
    "    dict:\n",
    "        Dictionary with words as keys and phonetic representation\n",
    "        as values for a given lang code\n",
    "    \"\"\"\n",
    "    print(f\"Downloading {iso_lang}\", end=\" \")\n",
    "    response = r.get(f\"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/{iso_lang}.txt\") \n",
    "    raw_data = response.text.split(\"\\n\")\n",
    "    print(f\"status:{response.status_code}\")\n",
    "    return response_to_dict(raw_data[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fd67538-015f-4177-a7c4-2ed578872216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading es_MX status:200\n"
     ]
    }
   ],
   "source": [
    "es_mx_ipa = get_ipa_dict(\"es_MX\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c0d50f-5a60-44f2-8234-a9e69a993304",
   "metadata": {},
   "source": [
    "```get_ipa_dict(iso_lang: str) -> dict:```\n",
    "Esta funci√≥n obtiene los datos del corpus desde GitHub para un idioma espec√≠fico (usando el c√≥digo ISO del idioma).\n",
    "Descarga el archivo de texto correspondiente al idioma especificado, lo procesa y lo convierte en un diccionario utilizando \n",
    "la funci√≥n response_to_dict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78a6d923-a939-4c05-ab9c-e8eb234be5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_ipa_transcriptions(word: str, dataset: dict) -> list[str]:\n",
    "    \"\"\"Search for a word in an IPA phonetics dict\n",
    " \n",
    "    Given a word this function return the IPA transcriptions\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    word: str\n",
    "        A word to search in the dataset\n",
    "    dataset: dict\n",
    "        A dataset for a given language code\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list[str]:\n",
    "        List with posible transcriptions if any, \n",
    "        else a list with the string \"NOT FOUND\" \n",
    "    \"\"\"\n",
    "    return dataset.get(word.lower(), \"NOT FOUND\").split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d3e291-4e7f-4505-8df1-2df7e8671b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/ma ùonesa/']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_ipa_transcriptions(\"mayonesa\", es_mx_ipa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c1291c-f712-4c42-aaf0-b16796a82dd5",
   "metadata": {},
   "source": [
    "```query_ipa_transcriptions(word: str, dataset: dict) -> list[str]:```\n",
    "Esta funci√≥n toma una palabra y un diccionario que contiene las palabras y sus transcripciones \n",
    "fon√©ticas, y devuelve una lista de posibles transcripciones fon√©ticas de la palabra dada. \n",
    "Si la palabra no se encuentra en el diccionario, devuelve una lista con el string \"NOT FOUND\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ccce02-e236-43a6-969f-0a8b304a6024",
   "metadata": {},
   "source": [
    "### Obtengamos un par de datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6accf39-2275-4359-aae6-4036c288d879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading es_MX status:200\n",
      "Downloading en_US status:200\n"
     ]
    }
   ],
   "source": [
    "dataset_mx = get_ipa_dict(\"es_MX\")\n",
    "dataset_us= get_ipa_dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebc420cc-ca6f-48f5-b754-7ca81f19f5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Ààw…™m…ôn/']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Simple query\n",
    "query_ipa_transcriptions(\"women\",dataset_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "134680ac-d4bb-4d69-b949-a4700b8705a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog -> ['/Ààd…î…°/']\n"
     ]
    }
   ],
   "source": [
    "print(f\"dog -> {query_ipa_transcriptions('dog',dataset_us)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2adefeb-5e1a-4b36-8d80-3445d26fb34e",
   "metadata": {},
   "source": [
    "**Diferentes formas de pronunciar dependiendo la lengua, aunque la ortografia se parezca. Ejemplo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "333646d1-2bc1-47ff-87e4-78357d540079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "espa√±ol hotel -> ['/otel/']\n",
      "ingles hotel -> ['/ho äÀàt…õ…´/']\n"
     ]
    }
   ],
   "source": [
    "#Ejemplo:\n",
    "print(\"espa√±ol \"+ f\"hotel -> {query_ipa_transcriptions('hotel',dataset_mx)}\")\n",
    "print(\"ingles \"+ f\"hotel -> {query_ipa_transcriptions('hotel',dataset_us)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e40d4d-5b0d-47cf-b53b-9297294f9c99",
   "metadata": {},
   "source": [
    "**Obteniendo Corpues desde GitHub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9031f6ba-d126-4377-9525-37c1853b42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_codes = {\n",
    "  \"ar\": \"Arabic (Modern Standard)\",\n",
    "  \"de\": \"German\",\n",
    "  \"en_UK\": \"English (Received Pronunciation)\",\n",
    "  \"en_US\": \"English (General American)\",\n",
    "  \"eo\": \"Esperanto\",\n",
    "  \"es_ES\": \"Spanish (Spain)\",\n",
    "  \"es_MX\": \"Spanish (Mexico)\",\n",
    "  \"fa\": \"Persian\",\n",
    "  \"fi\": \"Finnish\",\n",
    "  \"fr_FR\": \"French (France)\",\n",
    "  \"fr_QC\": \"French (Qu√©bec)\",\n",
    "  \"is\": \"Icelandic\",\n",
    "  \"ja\": \"Japanese\",\n",
    "  \"jam\": \"Jamaican Creole\",\n",
    "  \"km\": \"Khmer\",\n",
    "  \"ko\": \"Korean\",\n",
    "  \"ma\": \"Malay (Malaysian and Indonesian)\",\n",
    "  \"nb\": \"Norwegian Bokm√•l\",\n",
    "  \"nl\": \"Dutch\",\n",
    "  \"or\": \"Odia\",\n",
    "  \"ro\": \"Romanian\",\n",
    "  \"sv\": \"Swedish\",\n",
    "  \"sw\": \"Swahili\",\n",
    "  \"tts\": \"Isan\",\n",
    "  \"vi_C\": \"Vietnamese (Central)\",\n",
    "  \"vi_N\": \"Vietnamese (Northern)\",\n",
    "  \"vi_S\": \"Vietnamese (Southern)\",\n",
    "  \"yue\": \"Cantonese\",\n",
    "  \"zh\": \"Mandarin\"\n",
    "}\n",
    "iso_lang_codes = list(lang_codes.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbdb15d-4a40-4435-acb5-8bb53d7f26f6",
   "metadata": {},
   "source": [
    "Este c√≥digo define un diccionario llamado lang_codes que mapea c√≥digos ISO de idiomas a sus nombres correspondientes. Luego, crea una lista llamada iso_lang_codes que contiene solo los c√≥digos ISO de idiomas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf2a6c24-bf52-4135-bf3f-7bffa2112689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ar status:200\n",
      "Downloading de status:200\n",
      "Downloading en_UK status:200\n",
      "Downloading en_US status:200\n",
      "Downloading eo status:200\n",
      "Downloading es_ES status:200\n",
      "Downloading es_MX status:200\n",
      "Downloading fa status:200\n",
      "Downloading fi status:200\n",
      "Downloading fr_FR status:200\n",
      "Downloading fr_QC status:200\n",
      "Downloading is status:200\n",
      "Downloading ja status:200\n",
      "Downloading jam status:200\n",
      "Downloading km status:200\n",
      "Downloading ko status:200\n",
      "Downloading ma status:200\n",
      "Downloading nb status:200\n",
      "Downloading nl status:200\n",
      "Downloading or status:200\n",
      "Downloading ro status:200\n",
      "Downloading sv status:200\n",
      "Downloading sw status:200\n",
      "Downloading tts status:200\n",
      "Downloading vi_C status:200\n",
      "Downloading vi_N status:200\n",
      "Downloading vi_S status:200\n",
      "Downloading yue status:200\n",
      "Downloading zh status:404\n"
     ]
    }
   ],
   "source": [
    "def get_dataset() -> dict:\n",
    "    \"\"\"Download corpora from ipa-dict github\n",
    "\n",
    "    Given a list of iso lang codes download available datasets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Lang codes as keys and dictionary with words-transcriptions\n",
    "        as values\n",
    "    \"\"\"\n",
    "    return {code: get_ipa_dict(code) for code in iso_lang_codes}\n",
    "\n",
    "dataset = get_dataset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e4e059-ab92-4e28-8e66-c539c3a9cb0c",
   "metadata": {},
   "source": [
    "Despu√©s, se define una funci√≥n llamada get_dataset(). Esta funci√≥n no toma ning√∫n argumento y tiene como objetivo descargar conjuntos de datos de un repositorio de GitHub llamado \"ipa-dict\" para cada idioma en la lista de c√≥digos ISO de idiomas. La funci√≥n devuelve un diccionario donde las claves son los c√≥digos ISO de idiomas y los valores son los conjuntos de datos obtenidos para cada idioma.\n",
    "\n",
    "El diccionario dataset se inicializa llamando a la funci√≥n get_dataset(). Por lo tanto, dataset contendr√° datos de transcripci√≥n fon√©tica para cada idioma enumerado en lang_codes. Cada valor en el diccionario dataset ser√° otro diccionario que contiene las palabras y sus transcripciones fon√©ticas para el idioma correspondiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eeab29-b53c-42c6-a8c2-6ba5652d84b0",
   "metadata": {},
   "source": [
    "```{code: get_ipa_dict(code) for code in iso_lang_codes}```\n",
    "Es una expresi√≥n de diccionario con comprensi√≥n de lista. La comprensi√≥n de lista se utiliza para construir un diccionario en una sola l√≠nea de c√≥digo, utilizando un bucle for para iterar sobre una secuencia y generar pares clave-valor en el diccionario resultante.\n",
    "- {}: Indica que estamos creando un diccionario.\n",
    "- code: get_ipa_dict(code): Es la expresi√≥n que define cada par clave-valor en el diccionario. code es el nombre de la clave, y get_ipa_dict(code) es el valor asociado a esa clave. Aqu√≠, code es un elemento de la lista iso_lang_codes y get_ipa_dict(code) es una llamada a la funci√≥n get_ipa_dict() con code como argumento, lo que devuelve el conjunto de datos correspondiente al idioma code.\n",
    "- for code in iso_lang_codes: Esto itera sobre cada elemento en la lista iso_lang_codes, asignando cada elemento a la variable code.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6f1230-06fa-4ee4-8f8f-10bbfceab909",
   "metadata": {},
   "source": [
    "### Creando aplicaciones con estos datos\n",
    "1. **Buesquedas basicas automatizadas**  \n",
    "       Buscador de representaciones foneticas de palabras automatizado en diferentes idiomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d44523c-780a-4496-a845-a8f36987e04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representaci√≥n fon√©tica de palabras\n",
      "Lenguas disponibles:\n",
      "ar: Arabic (Modern Standard)\n",
      "de: German\n",
      "en_UK: English (Received Pronunciation)\n",
      "en_US: English (General American)\n",
      "eo: Esperanto\n",
      "es_ES: Spanish (Spain)\n",
      "es_MX: Spanish (Mexico)\n",
      "fa: Persian\n",
      "fi: Finnish\n",
      "fr_FR: French (France)\n",
      "fr_QC: French (Qu√©bec)\n",
      "is: Icelandic\n",
      "ja: Japanese\n",
      "jam: Jamaican Creole\n",
      "km: Khmer\n",
      "ko: Korean\n",
      "ma: Malay (Malaysian and Indonesian)\n",
      "nb: Norwegian Bokm√•l\n",
      "nl: Dutch\n",
      "or: Odia\n",
      "ro: Romanian\n",
      "sv: Swedish\n",
      "sw: Swahili\n",
      "tts: Isan\n",
      "vi_C: Vietnamese (Central)\n",
      "vi_N: Vietnamese (Northern)\n",
      "vi_S: Vietnamese (Southern)\n",
      "yue: Cantonese\n",
      "zh: Mandarin\n"
     ]
    }
   ],
   "source": [
    "print(\"Representaci√≥n fon√©tica de palabras\")\n",
    "\n",
    "print(\"Lenguas disponibles:\")\n",
    "for lang_key in dataset.keys():\n",
    "    print(f\"{lang_key}: {lang_codes[lang_key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2857a-54dd-4101-941d-a8b478b44169",
   "metadata": {},
   "source": [
    "Este bloque de c√≥digo imprime todos los idiomas disponibles y sus nombres correspondientes, utilizando el diccionario lang_codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8802529-fefa-4ee9-8f47-c5f64a8da6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "lang>>  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adios üëãüèº\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lang = input(\"lang>> \")\n",
    "print(f\"Selected language: {lang_codes[lang]}\") if lang else print(\"Adios üëãüèº\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4968f-82a1-44a6-996c-bb841e5ed19a",
   "metadata": {},
   "source": [
    "- El usuario debe ingresar el c√≥digo ISO del idioma que desee seleccionar.\n",
    "-   Si el usuario no ingresa ning√∫n c√≥digo (es decir, la cadena lang est√° vac√≠a), el programa imprime \"Adios üëãüèº\" y termina.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74254c30-a987-44d5-93b6-7ac97d272b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "while lang:\n",
    "    # El programa comeinza aqui\n",
    "    sub_data = dataset[lang]\n",
    "    query = input(f\"[{lang}] word>> \")\n",
    "    results = query_ipa_transcriptions(query, sub_data)\n",
    "    print(query, \" | \", results)\n",
    "    while query:\n",
    "        query = input(f\"[{lang}] word>> \")\n",
    "        if query:\n",
    "            results = query_ipa_transcriptions(query, sub_data)\n",
    "            print(query, \" | \", results)\n",
    "    lang = input(\"lang>> \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4657989-9e25-409a-b8e2-f6facdef0178",
   "metadata": {},
   "source": [
    "- Este bucle se ejecuta mientras lang no sea una cadena vac√≠a.\n",
    "- Dentro del bucle, se obtiene el conjunto de datos (sub_data) correspondiente al idioma seleccionado.\n",
    "- Luego, el programa solicita al usuario que ingrese una palabra (query) para buscar su representaci√≥n fon√©tica en el idioma seleccionado.\n",
    "- Se utilizan las funciones input() y query_ipa_transcriptions() para obtener la entrada del usuario y buscar las transcripciones fon√©ticas respectivamente.\n",
    "- Las transcripciones fon√©ticas y la palabra consultada se imprimen en la consola.\n",
    "- Despu√©s de cada b√∫squeda, el programa solicita al usuario que ingrese otra palabra para buscar su representaci√≥n fon√©tica en el mismo idioma.\n",
    "- Si el usuario ingresa una cadena vac√≠a como palabra de b√∫squeda, el bucle interno termina y el programa solicita al usuario que seleccione otro idioma (lang)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12ba24-0406-4f89-926a-603a8fcddfe2",
   "metadata": {},
   "source": [
    "### Encontrar las palabras que tengan terminacion similar\n",
    "Dado una oracion agrupar las palabras que tengan una pronuncacion similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81260a6b-c600-45b2-8f9e-f474b29208fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "…£o:: ['juego', 'fuego']\n",
      "on:: ['con', 'coraz√≥n']\n",
      " éa:: ['brilla', 'orilla']\n"
     ]
    }
   ],
   "source": [
    "#/ Utiliza transcripciones fon√©ticas para #\n",
    "# agrupar palabras de una oraci√≥n que tienen pronunciaciones \n",
    "# similares\n",
    "from collections import defaultdict\n",
    "\n",
    "#sentence = \"There once was a cat that ate a rat and after that sat on a yellow mat\"\n",
    "#sentence = \"the cat sat on the mat and looked at the rat.\"\n",
    "#sentence = \"If you drop the ball it will fall on the doll\"\n",
    "sentence = \"cuando juego con fuego siento como brilla la orilla de mi coraz√≥n\"\n",
    "\n",
    "#lang = \"en_US\"\n",
    "lang = \"es_MX\"\n",
    "words = sentence.split(\" \")\n",
    "\n",
    "# Get words and IPA transciptions map\n",
    "word_ipa_map = {}\n",
    "for word in words:\n",
    "    ipa_transcriptions = query_ipa_transcriptions(word.lower(), dataset.get(lang))\n",
    "    ipa_transcriptions = [_.strip(\"/\") for _ in ipa_transcriptions]\n",
    "    word_ipa_map.update({word.lower(): ipa_transcriptions})\n",
    "\n",
    "patterns = defaultdict(list)\n",
    "for word, ipa_list in word_ipa_map.items():\n",
    "    for ipa in ipa_list:\n",
    "        ipa_pattern = ipa[-2:]\n",
    "        patterns[ipa_pattern].append(word)\n",
    "\n",
    "for pattern, words in patterns.items():\n",
    "    if len(set(words)) > 1:\n",
    "        print(f\"{pattern}:: {words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88412525-9de4-4efd-b887-f20d999f7adc",
   "metadata": {},
   "source": [
    "**Obtenci√≥n de las transcripciones fon√©ticas para cada palabra:**\n",
    "- Se crea un diccionario llamado word_ipa_map donde las claves son las palabras y los valores son listas de sus transcripciones fon√©ticas en AFI.\n",
    "- Para cada palabra en la lista words, se llama a la funci√≥n query_ipa_transcriptions() para obtener sus transcripciones fon√©ticas en el idioma espec√≠fico (es_MX).\n",
    "- Se eliminan los caracteres \"/\" de las transcripciones fon√©ticas para limpiar los datos.\n",
    "- Las palabras y sus transcripciones fon√©ticas se almacenan en el diccionario word_ipa_map.\n",
    "  \n",
    "**Agrupaci√≥n de palabras por patr√≥n fon√©tico:**\n",
    "- Se crea un diccionario llamado patterns utilizando defaultdict(list). Esto permitir√° almacenar listas de palabras asociadas a un patr√≥n fon√©tico com√∫n.\n",
    "- Se itera sobre cada elemento del diccionario word_ipa_map, que contiene palabras y sus transcripciones fon√©ticas.\n",
    "- Para cada palabra, se itera sobre sus transcripciones fon√©ticas. Se toman las √∫ltimas dos letras de cada transcripci√≥n fon√©tica (ipa[-2:]) como un patr√≥n.\n",
    "- Se agrega la palabra a la lista correspondiente dentro del diccionario patterns, usando el patr√≥n fon√©tico como clave.\n",
    "\n",
    "**Impresion de los grupos de palabras con patrones similares**\n",
    "- Finalmente, se itera sobre el diccionario patterns.\n",
    "- Si el n√∫mero de palabras √∫nicas asociadas a un patr√≥n fon√©tico es mayor que uno, se imprime el patr√≥n fon√©tico junto con las palabras asociadas a √©l."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da131946-7b2d-4a88-87ef-063caebda71b",
   "metadata": {},
   "source": [
    "### Morfologia y analisis morfologico\n",
    "\n",
    "La morfolog√≠a es uno de los niveles de la lengua que estudia los procesos que conforman una palabra.\n",
    "\n",
    "**Morfemas**\n",
    "\n",
    "Con la morfolog√≠a podemos identificar como se modifica el significado variando la estructura de las palabras.\n",
    "\n",
    "Tenemos elementos m√≠nimos, intercambiables que varian el significado de las palabras: morfemas\n",
    "\n",
    "**Tipos de Morfemas**\n",
    "- Bases: Subcadenas que aportan informaci√≥n l√©xica de la palabra\n",
    "    - sol\n",
    "    - frasada\n",
    "- Afijos: Subcadenas que se adhieren a las bases para a√±adir informaci√≥n (flexiva, derivativa)\n",
    "    - Prefijos\n",
    "      - in-parable\n",
    "    - Subfijos\n",
    "      - pan-ecitos,come-mos\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989e1dbd-3cc6-46f4-8d2e-601dfd2286e9",
   "metadata": {},
   "source": [
    "### Aplicaciones relacionadas:\n",
    "**Analisis morfologico**\n",
    "\n",
    "La morfologia es uno de los niveles mas basicos del lenguaje\n",
    "que se puede estudiar. En ese sentido, una de las tareas\n",
    "mas basicas del NLP es el analisis morfologico.\n",
    "\n",
    "> El analisis morfologico es la determinacion de las partes que componen la palabra y su representacion linguistica, es una especie de etiquetado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951a0d29-8a5e-4eb1-a931-11c2f807e393",
   "metadata": {},
   "source": [
    "Los elementos morfol√≥gicos son analizados para:\n",
    "- Determinar la funci√≥n morfol√≥gica de las palabras\n",
    "- Hacer filtrado y pre-procesamiento de texto\n",
    "\n",
    "**Ejemplo**\n",
    "\n",
    "Parsing con expresiones regulares\n",
    "\n",
    "La estructura del sustantivo en espa√±ol es: ```BASE+AFIJOS (marcas flexivas)   --> Base+DIM+GEN+NUM```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f85c7bd-b406-4cc8-bae9-d70f68932cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras = [\n",
    "    'ni√±o',\n",
    "    'ni√±os',\n",
    "    'ni√±as',\n",
    "    'ni√±itos',\n",
    "    'gato',\n",
    "    'gatos',\n",
    "    'gatitos',\n",
    "    'perritos',\n",
    "    'paloma',\n",
    "    'palomita',\n",
    "    'palomas',\n",
    "    'flores',\n",
    "    'flor',\n",
    "    'florecita',\n",
    "    'l√°piz',\n",
    "    'l√°pices',\n",
    "    #'chiquitititititos',\n",
    "    #'curriculum', # curricula\n",
    "    #'campus', # campi\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e754e8-8efa-4fb3-968e-08028c415e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# esta funci√≥n aplica reglas morfol√≥gicas a una lista de palabras utilizando expresiones regulares para\n",
    "# capturar ciertos morfemas y realizar un an√°lisis morfol√≥gico. \n",
    "# Cada regla morfol√≥gica define un patr√≥n espec√≠fico que se busca y reemplaza en las palabras de entrada.\n",
    "\n",
    "def morph_parser_rules(words: list[str]) -> list[str]:\n",
    "    \"\"\"Aplica reglas morfol√≥gicas a una lista de palabras para realizar\n",
    "    un an√°lisis morfol√≥gico.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    words : list of str\n",
    "        Lista de palabras a las que se les aplicar√°n las reglas morfol√≥gicas.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list of str\n",
    "        Una lista de palabras despu√©s de aplicar las reglas morfol√≥gicas.\n",
    "    \"\"\"\n",
    "\n",
    "    #Lista para guardar las palabras parseadas\n",
    "    morph_parsing = []\n",
    "\n",
    "    # Reglas que capturan ciertos morfemas\n",
    "    # {ecita, itos, as, os}\n",
    "    for w in words:\n",
    "        #ecit -> DIM\n",
    "        R0 = re.sub(r'([^ ]+)ecit([a|o|as|os])', r'\\1-DIM\\2', w)\n",
    "        #it -> DIM\n",
    "        R1 = re.sub(r'([^ ]+)it([a|o|as|os])', r'\\1-DIM\\2', R0)\n",
    "        #a(s) -> FEM\n",
    "        R2 = re.sub(r'([^ ]+)a(s)', r'\\1-FEM\\2', R1)\n",
    "        #a -> FEM\n",
    "        R3 = re.sub(r'([^ ]+)a\\b', r'\\1-FEM', R2)\n",
    "        #o(s) -> MSC\n",
    "        R4 = re.sub(r'([^ ]+)o(s)', r'\\1-MSC\\2', R3)\n",
    "        #o .> MSC\n",
    "        R5 = re.sub(r'([^ ]+)o\\b', r'\\1-MSC', R4)\n",
    "        #es -> PL\n",
    "        R6 = re.sub(r'([^ ]+)es\\b', r'\\1-PL', R5)\n",
    "        #s -> PL\n",
    "        R7 = re.sub(r'([^ ]+)s\\b', r'\\1-PL', R6)\n",
    "        #Sustituye la c por z cuando es necesario\n",
    "        parse = re.sub(r'c-', r'z-', R7)\n",
    "\n",
    "        #Guarda los parseos\n",
    "        morph_parsing.append(parse)\n",
    "    return morph_parsing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926a894-466b-4548-8ede-ccf1ba75b9f9",
   "metadata": {},
   "source": [
    "Esta funci√≥n ```morph_parser_rules``` toma una lista de palabras como entrada y aplica una serie de reglas morfol√≥gicas para realizar un an√°lisis morfol√≥gico de las palabras.\n",
    "- Exporta re biblioteca de expresiones regulares\n",
    "- Se define la funci√≥n morph_parser_rules que recibe una lista de palabras como entrada y devuelve una lista de palabras despu√©s de aplicar las reglas morfol√≥gicas.\n",
    "- Se inicializa una lista vac√≠a morph_parsing que se utilizar√° para almacenar las palabras parseadas.\n",
    "- Se definen una serie de reglas morfol√≥gicas mediante expresiones regulares para capturar ciertos morfemas en las palabras:\n",
    "\n",
    "    Por ejemplo, ([^ ]+)ecit([a|o|as|os]) captura palabras que terminan en \"ecit\" seguido de \"a\", \"o\", \"as\" o \"os\".\n",
    "    Cada regla tiene un patr√≥n similar que se utiliza para buscar y reemplazar los morfemas espec√≠ficos.\n",
    "    Estos morfemas pueden ser sufijos que indican g√©nero (FEM para femenino, MSC para masculino), n√∫mero (PL para plural), etc.\n",
    "- Se aplican las reglas morfol√≥gicas a cada palabra en la lista de palabras de entrada utilizando el m√©todo sub del m√≥dulo re. Cada regla se aplica secuencialmente para obtener el resultado final.\n",
    "- Se agrega la palabra parseada a la lista morph_parsing.\n",
    "- Finalmente, se devuelve la lista de palabras parseadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4975467a-f2e9-49ca-a0c7-baa8c53b04c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ni√±o --> ni√±-MSC\n",
      "ni√±os --> ni√±-MSC-PL\n",
      "ni√±as --> ni√±-FEM-PL\n",
      "ni√±itos --> ni√±-DIM-MSC-PL\n",
      "gato --> gat-MSC\n",
      "gatos --> gat-MSC-PL\n",
      "gatitos --> gat-DIM-MSC-PL\n",
      "perritos --> perr-DIM-MSC-PL\n",
      "paloma --> palom-FEM\n",
      "palomita --> palom-DIM-FEM\n",
      "palomas --> palom-FEM-PL\n",
      "flores --> flor-PL\n",
      "flor --> flor\n",
      "florecita --> flor-DIM-FEM\n",
      "l√°piz --> l√°piz\n",
      "l√°pices --> l√°piz-PL\n"
     ]
    }
   ],
   "source": [
    "morph_parsing = morph_parser_rules(palabras)\n",
    "for palabra, parseo in zip(palabras, morph_parsing):\n",
    "    print(palabra, \"-->\", parseo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66de0cb9-5ece-424e-8389-bbee58ef15f6",
   "metadata": {},
   "source": [
    "Utiliza la ```funci√≥n morph_parser_rules``` para aplicar reglas morfol√≥gicas a una lista de palabras (palabras). Luego, utiliza un bucle for y la funci√≥n zip para iterar sobre ambas listas (palabras y morph_parsing) simult√°neamente e imprimir cada palabra junto con su parseo. Aqu√≠ est√° el c√≥digo completo:\n",
    "- Se define una lista de palabras palabras que contiene palabras en espa√±ol, algunas en singular y otras en plural, y con diferentes g√©neros.\n",
    "- Se llama a la funci√≥n morph_parser_rules pasando la lista de palabras como argumento. Esto aplica las reglas morfol√≥gicas definidas en la funci√≥n a cada palabra y devuelve una lista de palabras parseadas.\n",
    "- Se utiliza un bucle for junto con la funci√≥n zip para iterar simult√°neamente sobre las listas palabras y morph_parsing.\n",
    "- En cada iteraci√≥n del bucle, se imprime la palabra original junto con su parseo\n",
    "\n",
    "Este c√≥digo imprimir√° cada palabra de la lista palabras junto con su correspondiente parseo, mostrando el an√°lisis morfol√≥gico aplicado a cada una de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957921c7-34ed-4282-8b39-656af850bb4c",
   "metadata": {},
   "source": [
    "### Corpus: Shared Task en segmentacion morfologica\n",
    "\n",
    "- Shared task donde se busca convertir las palabras en una secuencia de morfemas\n",
    "- Segmentacion a nivle de palabras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3535e5-8a6b-4b5e-ac7f-18b9eff3330b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'astron√≥mica\\tastron√≥mico @@a\\t100\\nresignifiques\\tresignificar @@es\\t100\\nimportunamente\\timportuno @@mente'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtencion del corpus\n",
    "response = r.get(\"https://raw.githubusercontent.com/sigmorphon/2022SegmentationST/main/data/spa.word.test.gold.tsv\")\n",
    "response.text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "171ec545-ecb0-4238-9ec1-709e46ac1d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astron√≥mica\\tastron√≥mico @@a\\t100',\n",
       " 'resignifiques\\tresignificar @@es\\t100',\n",
       " 'importunamente\\timportuno @@mente\\t010',\n",
       " 'conjeturar√≠amos\\tconjeturar @@r√≠a @@amos\\t100',\n",
       " 'adquiridla\\tadquirir @@id @@la\\t100',\n",
       " 'deslocalizadla\\tdes @@local @@izar @@ad @@la\\t110',\n",
       " 'azafr√°nenla\\tazafr√°n @@ar @@en @@la\\t110',\n",
       " 'abocinado\\tabocinar @@ado\\t100',\n",
       " 'm√°jalo\\tmajar @@√° @@lo\\t100',\n",
       " 'troquelabais\\ttroquel @@ar @@ba @@ais\\t110']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = response.text.split(\"\\n\")\n",
    "raw_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b269e7d-f0dc-4013-bc9c-e801b61a7c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['astron√≥mico', '@@a']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element = raw_data[0].split(\"\\t\")\n",
    "element[1].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd632f4d-a8cb-4305-8ba9-18a528086fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "astron√≥mica astron√≥mico @@a 100\n",
      "['astron√≥mico', '@@a']\n",
      "resignifiques resignificar @@es 100\n",
      "['resignificar', '@@es']\n",
      "importunamente importuno @@mente 010\n",
      "['importuno', '@@mente']\n",
      "conjeturar√≠amos conjeturar @@r√≠a @@amos 100\n",
      "['conjeturar', '@@r√≠a', '@@amos']\n",
      "adquiridla adquirir @@id @@la 100\n",
      "['adquirir', '@@id', '@@la']\n",
      "deslocalizadla des @@local @@izar @@ad @@la 110\n",
      "['des', '@@local', '@@izar', '@@ad', '@@la']\n",
      "azafr√°nenla azafr√°n @@ar @@en @@la 110\n",
      "['azafr√°n', '@@ar', '@@en', '@@la']\n",
      "abocinado abocinar @@ado 100\n",
      "['abocinar', '@@ado']\n",
      "m√°jalo majar @@√° @@lo 100\n",
      "['majar', '@@√°', '@@lo']\n",
      "troquelabais troquel @@ar @@ba @@ais 110\n",
      "['troquel', '@@ar', '@@ba', '@@ais']\n"
     ]
    }
   ],
   "source": [
    "for row in raw_data[:10]:\n",
    "    word, morphs,category = row.split(\"\\t\")\n",
    "    print(word,morphs,category)\n",
    "    print(morphs.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d59ad8b-242f-44cb-87fa-10644b8fd10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "LANGS = {\n",
    "    \"ces\": \"Czech\",\n",
    "    \"eng\": \"English\",\n",
    "    \"fra\": \"French\",\n",
    "    \"hun\": \"Hungarian\",\n",
    "    \"spa\": \"Spanish\",\n",
    "    \"ita\": \"Italian\",\n",
    "    \"lat\": \"Latin\",\n",
    "    \"rus\": \"Russian\",\n",
    "}\n",
    "CATEGORIES = {\n",
    "    \"100\": \"Inflection\",\n",
    "    \"010\": \"Derivation\",\n",
    "    \"101\": \"Inflection, Compound\",\n",
    "    \"000\": \"Root\",\n",
    "    \"011\": \"Derivation, Compound\",\n",
    "    \"110\": \"Inflection, Derivation\",\n",
    "    \"001\": \"Compound\",\n",
    "    \"111\": \"Inflection, Derivation, Compound\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58511055-0481-4b9b-81bc-ba2d074d7766",
   "metadata": {},
   "source": [
    "Estas funciones est√°n dise√±adas para ayudar en la obtenci√≥n y procesamiento de archivos de datos TSV (valores separados por tabulaciones) desde una URL base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7367ad77-06d5-4290-a233-414746413000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Genera los nombres de archivo basados en el idioma y el track\n",
    "def get_files(lang: str, track: str = \"word\") -> list[str]:\n",
    "    \"\"\"Genera una lista de nombres de archivo basados en el idioma y el track\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    lang : str\n",
    "        Idioma para el cual se generar√°n los nombres de archivo.\n",
    "    track : str, optional\n",
    "        Track del shared task de donde vienen los datos (por defecto es \"word\").\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list[str]\n",
    "        Una lista de nombres de archivo generados para el idioma y el track especificados.\n",
    "    \"\"\"\n",
    "    base = f\"{lang}.{track}\"\n",
    "    return [\n",
    "        f\"{base}.dev.tsv\",\n",
    "        #f\"{base}.train.tsv\",\n",
    "        f\"{base}.test.gold.tsv\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b77300-91e0-406b-a6de-6113a941e8e7",
   "metadata": {},
   "source": [
    "`get_files(lang: str, track: str = \"word\") -> list[str]:`\n",
    "\n",
    "Esta funci√≥n genera una lista de nombres de archivo basados en el idioma y el track especificados. \n",
    "\n",
    "Toma dos argumentos: lang (el idioma para el cual se generar√°n los nombres de archivo) y track (el track del shared task del cual provienen los datos, por defecto es \"word\").\n",
    "\n",
    "Devuelve una lista de nombres de archivo generados para el idioma y el track especificados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5675631-15bc-4e7b-85c3-933c73f1b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga y concatena los datos de estos archivos.\n",
    "def get_raw_corpus(files: list) -> list:\n",
    "    \"\"\"Descarga y concatena los datos de los archivos tsv desde una URL base.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    files : list\n",
    "        Lista de nombres de archivos (sin extensi√≥n) que se descargar√°n\n",
    "        y concatenar√°n.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    list\n",
    "        Una lista que contiene los contenidos descargados y concatenados\n",
    "        de los archivos tsv.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for file in files:\n",
    "        print(f\"Downloading {file}.tsv\")\n",
    "        response = r.get(f\"https://raw.githubusercontent.com/sigmorphon/2022SegmentationST/main/data/{file}\")\n",
    "        response_list = response.text.split(\"\\n\")\n",
    "        result.extend(response_list[:-1]) # Last element is empty string ''\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215df804-48aa-4abd-96cc-f1bbd300fe5c",
   "metadata": {},
   "source": [
    "`get_raw_corpus(files: list) -> list:`\n",
    "\n",
    "Esta funci√≥n descarga y concatena los datos de los archivos TSV desde una URL base. Toma una lista de nombres de archivos (sin extensi√≥n) como entrada y devuelve una lista que contiene los contenidos descargados y concatenados de los archivos TSV. Cada elemento de la lista de entrada se considera como un nombre base de archivo que se completa con \".dev.tsv\" y \".test.gold.tsv\" para descargar los archivos correspondientes. La funci√≥n descarga los archivos, los divide en l√≠neas usando \"\\n\" como delimitador y los agrega a la lista result. Luego, devuelve esta lista que contiene los contenidos descargados y concatenados de los archivos TSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55aefd71-5f71-440a-a400-1d14b625ffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ita.word.dev.tsv.tsv\n",
      "Downloading ita.word.test.gold.tsv.tsv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['relassato\\trelassare @@ato\\t100',\n",
       " 'trituro\\ttritura @@are @@o\\t110',\n",
       " 'piastrellavamo\\tpiastrellare @@avamo\\t100',\n",
       " 'riaffollato\\tri @@a @@folla @@are @@ato\\t110',\n",
       " 'collose\\tcolla @@oso @@e\\t110',\n",
       " 'elettroforo\\telettro @@foro\\t010',\n",
       " 'progettiamo\\tprogettare @@iamo\\t100',\n",
       " 'islamofobico\\tislamofobia @@ico\\t010',\n",
       " 'addogava\\taddogare @@ava\\t100',\n",
       " 'disfamasse\\tdis @@fame @@are @@asse\\t110']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_raw_corpus(get_files(lang=\"ita\"))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03a860e2-bcb0-4312-8116-b4fb6088643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toma una lista de datos de corpus y un idioma como entrada,\n",
    "# y devuelve un DataFrame de pandas que contiene los datos del corpus procesados.\n",
    "def raw_corpus_to_dataframe(corpus_list: list, lang: str) -> pd.DataFrame:\n",
    "    \"\"\"Convierte una lista de datos de corpus en un DataFrame\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    corpus_list : list\n",
    "        Lista de l√≠neas del corpus a convertir en DataFrame.\n",
    "    lang : str\n",
    "        Idioma al que pertenecen los datos del corpus.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Un DataFrame de pandas que contiene los datos del corpus procesados.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for row in corpus_list:\n",
    "        try:\n",
    "            word, morphs, category = row.split(\"\\t\")\n",
    "        except ValueError:\n",
    "            # Caso donde no hay categoria\n",
    "            word, morphs = row.split(\"\\t\")\n",
    "            category = \"N/A\"\n",
    "        morphs = morphs.split()\n",
    "        data.append({\"words\": word, \"morphs\": morphs, \"category\": category, \"lang\": lang})\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"word_len\"] = df[\"words\"].apply(lambda x: len(x))\n",
    "    df[\"morphs_count\"] = df[\"morphs\"].apply(lambda x: len(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc99c8-253d-4cbc-a4e4-f11a2ce84007",
   "metadata": {},
   "source": [
    "- Se inicializa una lista vac√≠a data que se utilizar√° para almacenar los datos procesados del corpus.\n",
    "- Se itera sobre cada l√≠nea en la lista de datos del corpus (corpus_list). Cada l√≠nea contiene informaci√≥n sobre una palabra en el corpus.\n",
    "- Se intenta dividir la l√≠nea en tres partes utilizando el car√°cter de tabulaci√≥n como delimitador. Si la l√≠nea no tiene tres partes, se asume que no hay una categor√≠a y se maneja el caso donde no hay categor√≠a.\n",
    "- Se divide la cadena de morfemas en una lista de morfemas utilizando el espacio como delimitador.\n",
    "- Se agrega un diccionario a la lista data para cada palabra, que contiene la palabra, los morfemas, la categor√≠a (o \"N/A\" si no hay categor√≠a) y el idioma al que pertenecen los datos del corpus.\n",
    "- Se crea un DataFrame de pandas a partir de la lista data.\n",
    "- Se agrega una columna al DataFrame que contiene la longitud de cada palabra (word_len).\n",
    "- Se agrega una columna al DataFrame que contiene el n√∫mero de morfemas para cada palabra (morphs_count).\n",
    "- Finalmente, se devuelve el DataFrame df que contiene los datos del corpus procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adc64ce3-7677-4ef9-8e5e-fb224ec037cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading spa.word.dev.tsv.tsv\n",
      "Downloading spa.word.test.gold.tsv.tsv\n"
     ]
    }
   ],
   "source": [
    "# Descarga, procesa y almacena los datos de un corpus en espa√±ol en un DataFrame de pandas\n",
    "# para su posterior an√°lisis y procesamiento.\n",
    "files = get_files(\"spa\")\n",
    "raw_data = get_raw_corpus(files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3b8456-b4d4-4309-9473-e2e36309366c",
   "metadata": {},
   "source": [
    "1. Se utiliza la funci√≥n get_files(\"spa\") para obtener una lista de nombres de archivos para el idioma espa√±ol y el track \"word\". La funci√≥n devuelve una lista que contiene los nombres de archivo generados para el idioma y el track especificados.\n",
    "\n",
    "2. Se utiliza la funci√≥n get_raw_corpus(files) para descargar y concatenar los datos de los archivos TSV correspondientes a los nombres de archivo obtenidos anteriormente. Esta funci√≥n descarga los datos desde una URL base y devuelve una lista que contiene los contenidos descargados y concatenados de los archivos TSV.\n",
    "\n",
    "3. Finalmente, se utiliza la funci√≥n raw_corpus_to_dataframe(raw_data, lang=\"spa\") para convertir la lista de datos del corpus en un DataFrame de pandas. Esta funci√≥n procesa los datos del corpus, dividiendo cada l√≠nea en palabras, morfemas y categor√≠a (si est√° presente), y crea un DataFrame con estas columnas. Adem√°s, agrega columnas adicionales al DataFrame que contienen la longitud de cada palabra y el n√∫mero de morfemas para cada palabra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29fab853-69e9-420a-ac3c-58e23051533a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>morphs</th>\n",
       "      <th>category</th>\n",
       "      <th>lang</th>\n",
       "      <th>word_len</th>\n",
       "      <th>morphs_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mimbreadlas</td>\n",
       "      <td>[mimbre, @@ar, @@ad, @@las]</td>\n",
       "      <td>110</td>\n",
       "      <td>spa</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>erupcionado</td>\n",
       "      <td>[erupci√≥n, @@ar, @@ado]</td>\n",
       "      <td>110</td>\n",
       "      <td>spa</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>acob√≠jalo</td>\n",
       "      <td>[a, @@cobijar, @@√°, @@lo]</td>\n",
       "      <td>110</td>\n",
       "      <td>spa</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>holonom√≠as</td>\n",
       "      <td>[holonom√≠a, @@s]</td>\n",
       "      <td>100</td>\n",
       "      <td>spa</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tricotemos</td>\n",
       "      <td>[tricotar, @@emos]</td>\n",
       "      <td>100</td>\n",
       "      <td>spa</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172168</th>\n",
       "      <td>confi√°remos</td>\n",
       "      <td>[confiar, @@are, @@emos]</td>\n",
       "      <td>100</td>\n",
       "      <td>spa</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172169</th>\n",
       "      <td>granaba</td>\n",
       "      <td>[grano, @@ar, @@ba]</td>\n",
       "      <td>110</td>\n",
       "      <td>spa</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172170</th>\n",
       "      <td>granicen</td>\n",
       "      <td>[grano, @@izo, @@ar, @@en]</td>\n",
       "      <td>110</td>\n",
       "      <td>spa</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172171</th>\n",
       "      <td>cachete√©moslos</td>\n",
       "      <td>[cacha, @@ete, @@ear, @@emos, @@los]</td>\n",
       "      <td>110</td>\n",
       "      <td>spa</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172172</th>\n",
       "      <td>sum√°rieles</td>\n",
       "      <td>[sumario, @@ar, @@e, @@les]</td>\n",
       "      <td>110</td>\n",
       "      <td>spa</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172173 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 words                                morphs category lang  \\\n",
       "0          mimbreadlas           [mimbre, @@ar, @@ad, @@las]      110  spa   \n",
       "1          erupcionado               [erupci√≥n, @@ar, @@ado]      110  spa   \n",
       "2            acob√≠jalo             [a, @@cobijar, @@√°, @@lo]      110  spa   \n",
       "3           holonom√≠as                      [holonom√≠a, @@s]      100  spa   \n",
       "4           tricotemos                    [tricotar, @@emos]      100  spa   \n",
       "...                ...                                   ...      ...  ...   \n",
       "172168     confi√°remos              [confiar, @@are, @@emos]      100  spa   \n",
       "172169         granaba                   [grano, @@ar, @@ba]      110  spa   \n",
       "172170        granicen            [grano, @@izo, @@ar, @@en]      110  spa   \n",
       "172171  cachete√©moslos  [cacha, @@ete, @@ear, @@emos, @@los]      110  spa   \n",
       "172172      sum√°rieles           [sumario, @@ar, @@e, @@les]      110  spa   \n",
       "\n",
       "        word_len  morphs_count  \n",
       "0             11             4  \n",
       "1             11             3  \n",
       "2              9             4  \n",
       "3             10             2  \n",
       "4             10             2  \n",
       "...          ...           ...  \n",
       "172168        11             3  \n",
       "172169         7             3  \n",
       "172170         8             4  \n",
       "172171        14             5  \n",
       "172172        10             4  \n",
       "\n",
       "[172173 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = raw_corpus_to_dataframe(raw_data,lang=\"spa\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57129841-c5e9-4aa1-b499-893d87e229e3",
   "metadata": {},
   "source": [
    "**Analisis Cuantitativo para el Espa√±ol**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fca1ab4c-b027-411c-872e-c86952032961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "100    84377\n",
       "110    78803\n",
       "010     5710\n",
       "000     3059\n",
       "101      118\n",
       "001       58\n",
       "111       36\n",
       "011       12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ba563ef-1462-49d1-a3d6-a149bbdd89ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.236227515347935"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"morphs_count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d808df4f-75fa-4327-b818-75679d0eb684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.688301882408972"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"word_len\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54a45045-be91-422c-95f5-d1d5e6127b0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae032dc5-71ce-4a9f-9775-114114521663",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df[\"word_len\"], bins=10, edgecolor=\"black\")\n",
    "plt.xlabel(\"Word len\")\n",
    "plt.ylabel(\"Freq\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
