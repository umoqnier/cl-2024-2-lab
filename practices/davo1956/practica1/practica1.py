# -*- coding: utf-8 -*-
"""Practica1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Fv3s_repbhKaruiZ0QPVxYifaifK-_YZ

# Practica 01

Alumno: David P√©rez Jacome \\
N√∫mero de Cuenta: 316330420

1. Agregar un nuevo modo de b√∫squeda donde se extienda el comportamiento b√°sico del buscador para ahora buscar por frases. Ejemplo:
- [es_MX]>>> Hola que hace \\
 /ola/ /ke/ /ase/
"""

# Explorando el corpus
import requests as r

response = r.get("https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/en_US.txt")
response.text[:100]

from pprint import pprint as pp
ipa_data = response.text.split("\n")
#print(ipa_data[-4:])
ipa_data[-1]
pp(ipa_data[400:410])

"""Funciones necesarias de la clase:"""

def response_to_dict(ipa_list: list) -> dict:
    result = {}
    for item in ipa_list:
       item_list = item.split("\t")
       result[item_list[0]] = item_list[1]
    return result


def get_ipa_dict(iso_lang: str) -> dict:
    print(f"Downloading {iso_lang}", end=" ")
    response = r.get(f"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/{iso_lang}.txt")
    raw_data = response.text.split("\n")
    print(f"status:{response.status_code}")
    return response_to_dict(raw_data[:-1])

def query_ipa_transcriptions(word: str, dataset: dict) -> list[str]:
    return dataset.get(word.lower(), "NOT FOUND").split(", ")

##Esta funcion la usaremos para las frases:

def query_ipa_transcriptions_phrase(phrase: str, dataset: dict) -> list[str]:
    words = phrase.lower().split()
    results = [query_ipa_transcriptions(word, dataset) for word in words]
    return [transcription for sublist in results for transcription in sublist]

"""Funci√≥n para obtenert los datasets"""

# Get datasets
lang_codes = {
  "ar": "Arabic (Modern Standard)",
  "de": "German",
  "en_UK": "English (Received Pronunciation)",
  "en_US": "English (General American)",
  "eo": "Esperanto",
  "es_ES": "Spanish (Spain)",
  "es_MX": "Spanish (Mexico)",
  "fa": "Persian",
  "fi": "Finnish",
  "fr_FR": "French (France)",
  "fr_QC": "French (Qu√©bec)",
  "is": "Icelandic",
  "ja": "Japanese",
  "jam": "Jamaican Creole",
  "km": "Khmer",
  "ko": "Korean",
  "ma": "Malay (Malaysian and Indonesian)",
  "nb": "Norwegian Bokm√•l",
  "nl": "Dutch",
  "or": "Odia",
  "ro": "Romanian",
  "sv": "Swedish",
  "sw": "Swahili",
  "tts": "Isan",
  "vi_C": "Vietnamese (Central)",
  "vi_N": "Vietnamese (Northern)",
  "vi_S": "Vietnamese (Southern)",
  "yue": "Cantonese",
  "zh": "Mandarin"
}
iso_lang_codes = list(lang_codes.keys())

def get_dataset() -> dict:
    return {code: get_ipa_dict(code) for code in iso_lang_codes}

dataset = get_dataset()

"""Creando aplicaciones con estos datos
1. Busquedas b√°sicas automatizada.
"""

print("Representaci√≥n fon√©tica de palabras")

print("Lenguas disponibles:")
for lang_key in dataset.keys():
    print(f"{lang_key}: {lang_codes[lang_key]}")

lang = input("lang>> ")
print(f"Selected language: {lang_codes.get(lang, 'Not found')}") if lang else print("Adios")

while lang:
    sub_data = dataset[lang]
    mode = input(f"[{lang}] Choose mode (word/phrase)>> ").lower()

    if mode == "word":
        query = input(f"[{lang}] word>> ")
        results = query_ipa_transcriptions(query, sub_data)
        print(query, " | ", results)

        while query:
            query = input(f"[{lang}] word>> ")
            if query:
                results = query_ipa_transcriptions(query, sub_data)
                print(query, " | ", results)

    elif mode == "phrase":
        query = input(f"[{lang}] phrase>> ")
        results = query_ipa_transcriptions_phrase(query, sub_data)
        print(query, " | ", results)

        while query:
            query = input(f"[{lang}] phrase>> ")
            if query:
                results = query_ipa_transcriptions_phrase(query, sub_data)
                print(query, " | ", results)

    lang = input("lang>> ")

    ## A nuestro codigo anterior solo agregamos un nuevo modo llamado "phrase". El programa solicitar√° al usuario que elija entre "word" y "phrase". Si se elige "phrase", buscar√° la transcripci√≥n fon√©tica de cada palabra en la frase y las imprimir√° juntas.

"""2. Agregar un nuevo modo de b√∫squeda donde dada una palabra te muestre sus homofonos[1]. Debe mostrar su representaci√≥n IPA y la lista de homofonos (si existen). Ejemplo:

- [es_MX]>>> habares \\
/aŒ≤a…æes/ \\
['abares', 'habares', 'havares']\\

[1]: palabras con el mismo sonido pero distinta ortograf√≠a



"""

#agregamos la funcion para homofonos:
def query_homophones(word: str, dataset: dict) -> list[str]:
    transcription = dataset.get(word, "NOT FOUND")
    homophones = [k for k, v in dataset.items() if v == transcription and k != word]
    return homophones

print("Representaci√≥n fon√©tica de palabras")

print("Lenguas disponibles:")
for lang_key in dataset.keys():
    print(f"{lang_key}: {lang_codes[lang_key]}")

lang = input("lang>> ")
print(f"Selected language: {lang_codes.get(lang, 'Not found')}") if lang else print("Adios üëãüèº")

while lang:
    sub_data = dataset[lang]
    mode = input(f"[{lang}] Choose mode (word/phrase/homophones)>> ").lower()

    if mode == "word":
        query = input(f"[{lang}] word>> ")
        results = query_ipa_transcriptions(query, sub_data)
        print(query, " | ", results)

        while query:
            query = input(f"[{lang}] word>> ")
            if query:
                results = query_ipa_transcriptions(query, sub_data)
                print(query, " | ", results)

    elif mode == "phrase":
        query = input(f"[{lang}] phrase>> ")
        results = query_ipa_transcriptions_phrase(query, sub_data)
        print(query, " | ", results)

        while query:
            query = input(f"[{lang}] phrase>> ")
            if query:
                results = query_ipa_transcriptions_phrase(query, sub_data)
                print(query, " | ", results)

    elif mode == "homophones":
        query = input(f"[{lang}] word>> ")
        homophones = query_homophones(query, sub_data)
        if homophones:
            for homophone in homophones:
                homophone_transcription = sub_data[homophone]
                homophone_list = query_ipa_transcriptions(homophone, sub_data)
                print(f"{homophone} | {homophone_transcription}")
                print("Homophones: ", homophone_list)

        else:
            print(f"No homophones found for {query}")

        while query:
            query = input(f"[{lang}] word>> ")
            if query:
                homophones = query_homophones(query, sub_data)
                if homophones:
                    for homophone in homophones:
                        homophone_transcription = sub_data[homophone]
                        homophone_list = query_ipa_transcriptions(homophone, sub_data)
                        print(f"{homophone} | {homophone_transcription}")
                        print("Homophones: ", homophone_list)
                else:
                    print(f"No homophones found for {query}")

    lang = input("lang>> ")

"""3. Observe las distribuciones de longitud de palabra y de n√∫mero de morfemas por palabra para todas lenguas. Basado en esos datos, haga un comentario sobre las diferencias en morfolog√≠a de las lenguas

RESPUESTA: Para analizar la morfolog√≠a de diferentes lenguas, ser√≠a necesario tener acceso a un corpus de texto significativo en cada lengua, etiquetado con informaci√≥n morfol√≥gica. Herramientas espec√≠ficas para el an√°lisis morfol√≥gico, como analizadores morfol√≥gicos o etiquetadores POS (Part-of-Speech), tambi√©n ser√≠an √∫tiles.


"""