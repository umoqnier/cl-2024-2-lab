{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica 6\n",
    "### Modelos del lenguaje\n",
    "\n",
    "**Fecha de entrega**  \n",
    "21 de abril de 2024\n",
    "\n",
    "- Crear un par de modelos del lenguaje usando un corpus en español|\n",
    "    - Corpus: El Quijote\n",
    "    - URL: https://www.gutenberg.org/ebooks/2000\n",
    "    - Modelo de n-gramas con n = [2, 3]\n",
    "    - Hold out con test = 30% y train = 70%\n",
    "- Evaluar los modelos y reportar la perplejidad de cada modelo\n",
    "    - Comparar los resultados entre los diferentes modelos del lenguaje (bigramas, trigramas)\n",
    "    - ¿Cual fue el modelo mejor evaluado? ¿Porqué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: click in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Install dependencies\n",
    "\"\"\"\n",
    "\n",
    "%pip install nltk matplotlib numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download spanish language corpus\n",
    "\n",
    "El Quijote\n",
    "https://www.gutenberg.org/ebooks/2000\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://www.gutenberg.org/ebooks/2000.txt.utf-8\"\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('quijote.txt', 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence:\n",
      "['<BOS>', 'había', 'hecho', 'muestra', 'de', 'más', 'de', 'diez', 'pares', 'de', 'vestidos', 'y', 'de', 'más', 'de', 'veinte', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preprocessing\n",
    "\"\"\"\n",
    "\n",
    "import string\n",
    "\n",
    "\n",
    "with open('quijote.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "# perform preprocessing\n",
    "\n",
    "# trim lines\n",
    "text = [line.strip() for line in text if line.strip()]\n",
    "\n",
    "# make lowercase\n",
    "text = [line.lower() for line in text]\n",
    "\n",
    "# remove punctuation\n",
    "text = [''.join([c for c in line if c not in string.punctuation]) for line in text]\n",
    "\n",
    "# remove special characters and numbers\n",
    "text = [''.join([c for c in line if c.isalpha() or c == ' ']) for line in text]\n",
    "\n",
    "# add <BOS> and <EOS> tokens\n",
    "text = ['<BOS> ' + line + ' <EOS>' for line in text]\n",
    "\n",
    "# split into words\n",
    "text = [line.split() for line in text]\n",
    "\n",
    "\n",
    "print('example sentence:')\n",
    "print(text[np.random.randint(len(text))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "['<BOS>', 'hacer', 'un', 'rimero', 'dellos', 'y', 'pegarles', 'fuego', 'y', 'si', 'no', 'llevarlos', 'al', 'corral', 'y', '<EOS>']\n",
      "Test data:\n",
      "['<BOS>', 'así', 'es', 'verdad', 'replicó', 'don', 'quijote', 'porque', 'no', 'fuera', 'acertado', 'que', 'los', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split training and test data\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(text, test_size=0.2)\n",
    "\n",
    "# print out a random sample of the training data and the test data\n",
    "print('Training data:')\n",
    "print(train_data[np.random.randint(len(train_data))])\n",
    "print('Test data:')\n",
    "print(test_data[np.random.randint(len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative preprocessing using nltk\n",
    "\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# def preprocess(text):\n",
    "#     result = []\n",
    "#     for token in word_tokenize(text):\n",
    "#         if len(token) > 2 and token not in stopwords.words('english'):\n",
    "#             token = stemmer.stem(lemmatizer.lemmatize(token, pos='v'))  # Lemmatize and stem token\n",
    "#             result.append(token)\n",
    "#     return result\n",
    "\n",
    "# with open('quijote.txt', 'r', encoding='utf-8') as f:\n",
    "#     text = f.read()\n",
    "\n",
    "# processed_text = preprocess(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<BOS>', 'el', 'ingenioso'),\n",
       " ('el', 'ingenioso', 'hidalgo'),\n",
       " ('ingenioso', 'hidalgo', 'don'),\n",
       " ('hidalgo', 'don', 'quijote'),\n",
       " ('don', 'quijote', 'de'),\n",
       " ('quijote', 'de', 'la'),\n",
       " ('de', 'la', 'mancha'),\n",
       " ('la', 'mancha', '<EOS>')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import ngrams\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "list(ngrams(text[0], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train bi-gram model using nltk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train tri-gram model using nltk\n",
    "\"\"\"\n",
    "\n",
    "# a trigram model is a dictionary of dictionaries\n",
    "# by default the inner dictionary is a defaultdict with a default value of 0\n",
    "# i.e. if a key is not found in the dictionary, it will return 0\n",
    "# this is useful for counting the number of times a word appears after a bigram\n",
    "trigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for sentence in train_data:\n",
    "    for w1, w2, w3 in ngrams(sentence, 3):\n",
    "        trigram_model[(w1, w2)][w3] += 1\n",
    "\n",
    "trigram_model[\"<BOS>\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('<BOS>', 'que'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000002A717C37E20>, {'trata': 18, 'estás': 1, 'es': 18, 'será': 1, 'no': 62, 'me': 40, 'para': 4, 'los': 21, 'era': 10, 'ni': 3, 'se': 35, 'había': 9, 'temes': 1, 'a': 21, 'este': 3, 'la': 18, 'el': 24, 'en': 45, 'fue': 6, 'vais': 1, 'alborozado': 1, 'viene': 3, 'anduvistes': 1, 'yo': 23, 'si': 16, 'entre': 5, 'por': 11, 'cuenta': 1, 'lo': 13, 'volaban': 1, 'creo': 1, 'esta': 3, 'él': 16, 'damas': 1, 'solapar': 1, 'ana': 1, 'don': 4, 'repica': 1, 'como': 3, 'echalle': 1, 'son': 5, 'las': 10, 'del': 3, 'tengo': 8, 'os': 8, 'tenía': 3, 'luego': 1, 'resta': 1, 'iba': 2, 'volvió': 1, 'sus': 2, 'poco': 1, 'le': 25, 'nunca': 1, 'haya': 2, 'habiendo': 1, 'engañan': 1, 'queden': 1, 'al': 7, 'cuando': 8, 'con': 9, 'sancho': 7, 'ellos': 6, 'estáis': 1, 'tenga': 1, 'acertara': 1, 'iban': 2, 'aspiran': 1, 'aún': 4, 'tiene': 2, 'duermo': 1, 'venía': 2, 'puntualmente': 1, 'cual': 1, 'les': 4, 'según': 1, 'tenéis': 1, 'ese': 1, 'dijo': 1, 'par': 1, 'de': 20, 'más': 13, 'oyeron': 1, 'vuestra': 4, 'escuchado': 2, 'lástima': 1, 'pretendo': 1, 'representadas': 1, 'he': 3, 'fuera': 1, 'tienen': 1, 'eres': 3, 'dicen': 2, 'granizo': 1, 'salió': 1, 'tan': 3, 'ya': 8, 'quedábamos': 1, 'servirán': 1, 'concluyesen': 1, 'soy': 3, 'déstos': 1, 'estoy': 1, 'mira': 1, 'sea': 4, 'pudo': 2, 'pues': 1, 'siendo': 2, 'hay': 1, 'nos': 4, 'mirase': 1, 'hiciéremos': 1, 'amemos': 1, 'rayo': 1, 'salieron': 1, 'hace': 1, 'así': 7, 'éstos': 1, 'suelen': 1, 'una': 2, 'te': 10, 'mi': 5, 'templa': 1, 'duermen': 1, 'pueda': 3, 'curiosos': 1, 'cebada': 1, 'dejé': 1, 'cantaba': 1, 'dulcinea': 1, 'parece': 1, 'desto': 1, 'dondequiera': 1, 'puesto': 4, 'aquí': 3, 'junto': 1, 'quede': 1, 'muestra': 1, 'están': 2, 'remediados': 1, 'jamás': 2, 'aunque': 4, 'voy': 2, 'entraron': 1, 'paraba': 1, 'generalmente': 1, 'todos': 4, 'imagino': 1, 'perseverar': 1, 'puedo': 1, 'tenemos': 1, 'esto': 1, 'llevaba': 1, 'pudiesen': 1, 'ella': 3, 'diésemos': 1, 'has': 4, 'gandalín': 1, 'da': 1, 'acaso': 1, 'presto': 2, 'su': 4, 'todo': 4, 'hacéis': 1, 'lotario': 2, 'dejasen': 1, 'bien': 3, 'vieras': 1, 'dice': 2, 'profesan': 1, 'hacer': 1, 'todavía': 1, 'deis': 1, 'después': 3, 'estuviere': 1, 'deleiten': 1, 'parecía': 2, 'compra': 1, 'ansí': 1, 'un': 2, 'dices': 1, 'pasase': 1, 'algún': 2, 'andan': 2, 'quisieres': 1, 'tanto': 1, 'estar': 1, 'quiso': 1, 'ver': 2, 'entró': 1, 'allí': 3, 'encomendarme': 1, 'aquella': 1, 'rebuznaron': 1, 'tal': 2, 'vos': 3, 'habrá': 1, 'rompiendo': 1, 'tomes': 1, 'puso': 1, 'desde': 5, 'pocos': 1, 'otra': 2, 'estaba': 5, 'eran': 4, 'tiempo': 1, 'vivir': 1, 'suele': 1, 'sepa': 1, 'oh': 2, 'todas': 1, 'sí': 2, 'hombre': 1, 'hagas': 1, 'ata': 1, 'cada': 2, 'mereces': 1, 'acabó': 1, 'advirtiese': 1, 'mudando': 1, 'sé': 3, 'consigo': 1, 'pone': 1, 'perdimos': 1, 'sustentaré': 1, 'está': 2, 'hacía': 3, 'amada': 1, 'entonces': 2, 'agora': 1, 'ha': 3, 'debo': 1, 'hoy': 2, 'sin': 5, 'casas': 1, 'salieses': 1, 'oficio': 1, 'parte': 1, 'queda': 1, 'abrasa': 1, 'hice': 1, 'pidas': 1, 'pasaba': 2, 'pocas': 1, 'vee': 1, 'hizo': 1, 'mostrar': 1, 'sacó': 1, 'conocía': 1, 'quería': 1, 'decía': 2, 'apenas': 1, 'contra': 1, 'pienso': 1, 'habían': 1, 'cerca': 1, 'estos': 2, 'quieres': 1, 'dios': 1, 'toda': 1, 'justamente': 1, 'recibió': 1, 'mostraron': 1, 'pugnaba': 1, 'residen': 1, 'dorotea': 1, 'anduviesen': 1, 'fuese': 1, 'quien': 1, 'halló': 1, 'huye': 1, 'pueden': 1, 'nadie': 1, 'instigado': 1, 'vuesa': 1, 'tira': 1, 'digo': 1, 'mientras': 1, 'cuantas': 1, 'han': 3, 'camila': 1, 'pasa': 1, 'tocan': 2, 'llevó': 1, 'añadir': 1, 'quisiese': 1, 'tuvo': 2, 'justos': 1, 'quedan': 1, 'llegase': 1, 'hallándose': 1, 'viniere': 1, 'acreditó': 1, 'mañana': 1, 'quedaba': 1, 'pinta': 1, 'dïana': 1, 'vence': 1, 'llegan': 1, 'llevéis': 1, 'tras': 1, 'adondequiera': 1, 'puede': 1, 'daba': 1, 'felicemente': 1, 'grabó': 1, 'llovía': 1, 'tenían': 1, 'cantaban': 1, 'remitieron': 1, 'valiente': 1, 'valgan': 1, 'fuere': 1, 'prosigue': 1, 'amor': 1, 'quisiéredes': 1, 'sobre': 1, 'recibe': 1, 'tire': 1, 'quiera': 1, 'van': 1, 'alegra': 1, 'comiese': 1, 'reír': 1, 'sarna': 1, 'llegó': 1, 'éste': 1, 'estuvimos': 1, 'toca': 1, 'otros': 1, 'tiraba': 1, 'habíades': 1, 'cardenio': 1, 'muchos': 1, 'debéis': 1, 'zarpasen': 1, 'hiciese': 1}))\n",
      "(('que', 'trata'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000002A717C37D80>, {'de': 33, 'verdades': 1, 'del': 4}))\n",
      "(('trata', 'de'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000002A717C37CE0>, {'cosas': 3, 'la': 16, 'lo': 7, 'cómo': 4, 'las': 2, 'muchas': 2}))\n",
      "(('de', 'cosas'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000002A717C37C40>, {'tocantes': 3, 'sucedidas': 2, 'has': 1, 'que': 5, 'se': 1, 'de': 1, 'no': 1}))\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for entry in itertools.islice(trigram_model.items(), 4):\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY = set([word.lower() for sent in train_data for word in sent])\n",
    "VOCABULARY_SIZE = len(VOCABULARY) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_probabilities(model: defaultdict) -> defaultdict:\n",
    "    result = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for prefix in model:\n",
    "        # Todas las veces que vemos la key seguido de cualquier cosa\n",
    "        total = float(sum(model[prefix].values()))\n",
    "        for next_word in model[prefix]:\n",
    "            # Laplace smothing\n",
    "            # result[prefix][next_word] = (model[prefix][next_word] + 1) / (total + VOCABULARY_SIZE)\n",
    "            # Without smothing\n",
    "            result[prefix][next_word] = model[prefix][next_word] / total\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_probs = calculate_model_probabilities(trigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 0.07751937984496124),\n",
       " ('de', 0.05426356589147287),\n",
       " ('la', 0.05426356589147287),\n",
       " ('un', 0.050387596899224806),\n",
       " ('lo', 0.046511627906976744),\n",
       " ('<EOS>', 0.03875968992248062),\n",
       " ('una', 0.03488372093023256),\n",
       " ('menester', 0.031007751937984496),\n",
       " ('más', 0.031007751937984496),\n",
       " ('muy', 0.01937984496124031),\n",
       " ('tan', 0.01937984496124031),\n",
       " ('mi', 0.015503875968992248),\n",
       " ('caballero', 0.015503875968992248),\n",
       " ('posible', 0.015503875968992248),\n",
       " ('tal', 0.015503875968992248),\n",
       " ('como', 0.011627906976744186),\n",
       " ('verdad', 0.011627906976744186),\n",
       " ('gran', 0.011627906976744186),\n",
       " ('suyo', 0.011627906976744186),\n",
       " ('razón', 0.011627906976744186),\n",
       " ('a', 0.007751937984496124),\n",
       " ('uno', 0.007751937984496124),\n",
       " ('tarde', 0.007751937984496124),\n",
       " ('tiempo', 0.007751937984496124),\n",
       " ('vuestra', 0.007751937984496124),\n",
       " ('oficio', 0.007751937984496124),\n",
       " ('discreto', 0.007751937984496124),\n",
       " ('su', 0.007751937984496124),\n",
       " ('opinión', 0.007751937984496124),\n",
       " ('por', 0.007751937984496124),\n",
       " ('gente', 0.007751937984496124),\n",
       " ('mejor', 0.007751937984496124),\n",
       " ('nuestro', 0.007751937984496124),\n",
       " ('tanto', 0.007751937984496124),\n",
       " ('ahora', 0.007751937984496124),\n",
       " ('bueno', 0.007751937984496124),\n",
       " ('imposible', 0.003875968992248062),\n",
       " ('amado', 0.003875968992248062),\n",
       " ('contra', 0.003875968992248062),\n",
       " ('decir', 0.003875968992248062),\n",
       " ('bastante', 0.003875968992248062),\n",
       " ('moza', 0.003875968992248062),\n",
       " ('así', 0.003875968992248062),\n",
       " ('cristiano', 0.003875968992248062),\n",
       " ('juan', 0.003875968992248062),\n",
       " ('vuesa', 0.003875968992248062),\n",
       " ('eterna', 0.003875968992248062),\n",
       " ('algún', 0.003875968992248062),\n",
       " ('en', 0.003875968992248062),\n",
       " ('suplemento', 0.003875968992248062),\n",
       " ('mentirosa', 0.003875968992248062),\n",
       " ('lástima', 0.003875968992248062),\n",
       " ('al', 0.003875968992248062),\n",
       " ('cierto', 0.003875968992248062),\n",
       " ('mía', 0.003875968992248062),\n",
       " ('tuerta', 0.003875968992248062),\n",
       " ('villano', 0.003875968992248062),\n",
       " ('vuestro', 0.003875968992248062),\n",
       " ('grande', 0.003875968992248062),\n",
       " ('otro', 0.003875968992248062),\n",
       " ('que', 0.003875968992248062),\n",
       " ('mío', 0.003875968992248062),\n",
       " ('enseñar', 0.003875968992248062),\n",
       " ('si', 0.003875968992248062),\n",
       " ('vencido', 0.003875968992248062),\n",
       " ('señal', 0.003875968992248062),\n",
       " ('digna', 0.003875968992248062),\n",
       " ('poco', 0.003875968992248062),\n",
       " ('pensar', 0.003875968992248062),\n",
       " ('simple', 0.003875968992248062),\n",
       " ('pública', 0.003875968992248062),\n",
       " ('puerto', 0.003875968992248062),\n",
       " ('lacayo', 0.003875968992248062),\n",
       " ('dama', 0.003875968992248062),\n",
       " ('hombre', 0.003875968992248062),\n",
       " ('este', 0.003875968992248062),\n",
       " ('reina', 0.003875968992248062),\n",
       " ('determinación', 0.003875968992248062),\n",
       " ('cuando', 0.003875968992248062),\n",
       " ('fuerza', 0.003875968992248062),\n",
       " ('escudero', 0.003875968992248062),\n",
       " ('fama', 0.003875968992248062),\n",
       " ('abundantísimo', 0.003875968992248062),\n",
       " ('maravilla', 0.003875968992248062),\n",
       " ('deseosa', 0.003875968992248062),\n",
       " ('laberinto', 0.003875968992248062),\n",
       " ('buena', 0.003875968992248062),\n",
       " ('pura', 0.003875968992248062),\n",
       " ('algo', 0.003875968992248062),\n",
       " ('valentía', 0.003875968992248062),\n",
       " ('dulce', 0.003875968992248062),\n",
       " ('necedad', 0.003875968992248062),\n",
       " ('tamaña', 0.003875968992248062),\n",
       " ('prerrogativa', 0.003875968992248062),\n",
       " ('mala', 0.003875968992248062),\n",
       " ('proveedor', 0.003875968992248062),\n",
       " ('tanta', 0.003875968992248062),\n",
       " ('y', 0.003875968992248062),\n",
       " ('cristiana', 0.003875968992248062),\n",
       " ('olla', 0.003875968992248062),\n",
       " ('sutil', 0.003875968992248062),\n",
       " ('gentil', 0.003875968992248062),\n",
       " ('blanco', 0.003875968992248062),\n",
       " ('negro', 0.003875968992248062),\n",
       " ('pesar', 0.003875968992248062),\n",
       " ('amada', 0.003875968992248062),\n",
       " ('deseado', 0.003875968992248062),\n",
       " ('desati', 0.003875968992248062),\n",
       " ('respondió', 0.003875968992248062),\n",
       " ('predicar', 0.003875968992248062),\n",
       " ('mucha', 0.003875968992248062),\n",
       " ('peor', 0.003875968992248062),\n",
       " ('esta', 0.003875968992248062)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict(trigram_probs[\"que\", \"es\"]).items(), key=lambda x: -1 * x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cual', 0.04375), ('que', 0.034375), ('duque', 0.03125)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_likely_words(\n",
    "    model_probs: defaultdict, context: str, top_count: int = 10\n",
    ") -> list[tuple]:\n",
    "    \"\"\"Dado un contexto obtiene las palabras más probables\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    model_probs: defaultdict\n",
    "        Probabilidades del modelo\n",
    "    context: str\n",
    "        Contexto con el cual calcular las palabras más probables siguientes\n",
    "    top_count: int\n",
    "        Cantidad de palabras más probables. Default 10\n",
    "    \"\"\"\n",
    "    history = tuple(context.split())\n",
    "    return sorted(dict(model_probs[history]).items(), key=lambda prob: -1 * prob[1])[\n",
    "        :top_count\n",
    "    ]\n",
    "\n",
    "\n",
    "get_likely_words(trigram_probs, \"<BOS> el\", top_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for sentence in train_data:\n",
    "    for w1, w2 in ngrams(sentence, 2):\n",
    "        bigram_model[w1][w2] += 1\n",
    "\n",
    "bigram_probs = calculate_model_probabilities(bigram_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluate model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate perplexity\n",
    "\"\"\"\n",
    "\n",
    "# perplexity is a measure of how well a probability model predicts a sample\n",
    "# we will use test_data to calculate perplexity for a model trained with train_data\n",
    "\n",
    "perplexities = []\n",
    "for sentence in test_data:\n",
    "    log_prob = calculate_sentence_probability(bigram_probs, sentence, 2)\n",
    "    perplexity = -(log_prob / len(sentence) - 1)\n",
    "    perplexities.append(perplexity)\n",
    "\n",
    "total_perplexity = sum(perplexities) / len(perplexities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
