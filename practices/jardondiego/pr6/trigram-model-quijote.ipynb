{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica 6\n",
    "### Modelos del lenguaje\n",
    "\n",
    "**Fecha de entrega**  \n",
    "21 de abril de 2024\n",
    "\n",
    "- Crear un par de modelos del lenguaje usando un corpus en español|\n",
    "    - Corpus: El Quijote\n",
    "    - URL: https://www.gutenberg.org/ebooks/2000\n",
    "    - Modelo de n-gramas con n = [2, 3]\n",
    "    - Hold out con test = 30% y train = 70%\n",
    "- Evaluar los modelos y reportar la perplejidad de cada modelo\n",
    "    - Comparar los resultados entre los diferentes modelos del lenguaje (bigramas, trigramas)\n",
    "    - ¿Cual fue el modelo mejor evaluado? ¿Porqué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: click in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Install dependencies\n",
    "\"\"\"\n",
    "\n",
    "%pip install nltk matplotlib numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download spanish language corpus\n",
    "\n",
    "El Quijote\n",
    "https://www.gutenberg.org/ebooks/2000\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import string\n",
    "\n",
    "# url = \"https://www.gutenberg.org/ebooks/2000.txt.utf-8\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "# with open('quijote.txt', 'wb') as file:\n",
    "#     file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence:\n",
      "['<BOS>', 'y', 'describir', 'punto', 'por', 'punto', 'y', 'parte', 'por', 'parte', 'la', 'hermosura', 'de', 'la', 'sin', 'par', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preprocessing\n",
    "\"\"\"\n",
    "\n",
    "with open('quijote.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "# perform preprocessing\n",
    "\n",
    "# trim lines\n",
    "text = [line.strip() for line in text if line.strip()]\n",
    "\n",
    "# make lowercase\n",
    "text = [line.lower() for line in text]\n",
    "\n",
    "# remove punctuation\n",
    "text = [''.join([c for c in line if c not in string.punctuation]) for line in text]\n",
    "\n",
    "# remove special characters and numbers\n",
    "text = [''.join([c for c in line if c.isalpha() or c == ' ']) for line in text]\n",
    "\n",
    "# add <BOS> and <EOS> tokens\n",
    "text = ['<BOS> ' + line + ' <EOS>' for line in text]\n",
    "\n",
    "# split into words\n",
    "text = [line.split() for line in text]\n",
    "\n",
    "\n",
    "print('example sentence:')\n",
    "print(text[np.random.randint(len(text))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "['<BOS>', 'porque', 'eran', 'seis', 'medias', 'tinajas', 'que', 'cada', 'una', 'cabía', 'un', 'rastro', 'de', 'carne', 'así', '<EOS>']\n",
      "Test data:\n",
      "['<BOS>', 'donde', 'se', 'prosigue', 'la', 'noticia', 'que', 'tuvo', 'don', 'quijote', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split training and test data\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(text, test_size=0.2)\n",
    "\n",
    "# print out a random sample of the training data and the test data\n",
    "print('Training data:')\n",
    "print(train_data[np.random.randint(len(train_data))])\n",
    "print('Test data:')\n",
    "print(test_data[np.random.randint(len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<BOS>', 'den', 'entre'),\n",
       " ('den', 'entre', 'dos'),\n",
       " ('entre', 'dos', 'platos'),\n",
       " ('dos', 'platos', 'a'),\n",
       " ('platos', 'a', 'buen'),\n",
       " ('a', 'buen', 'seguro'),\n",
       " ('buen', 'seguro', 'que'),\n",
       " ('seguro', 'que', 'el'),\n",
       " ('que', 'el', 'caballo'),\n",
       " ('el', 'caballo', 'no'),\n",
       " ('caballo', 'no', 'la'),\n",
       " ('no', 'la', 'arrostre'),\n",
       " ('la', 'arrostre', '<EOS>')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import ngrams\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "list(ngrams(text[np.random.randint(len(text))], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train tri-gram model using nltk\n",
    "\"\"\"\n",
    "\n",
    "# a trigram model is a dictionary of dictionaries\n",
    "# by default the inner dictionary is a defaultdict with a default value of 0\n",
    "# i.e. if a key is not found in the dictionary, it will return 0\n",
    "# this is useful for counting the number of times a word appears after a bigram\n",
    "trigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for sentence in train_data:\n",
    "    for w1, w2, w3 in ngrams(sentence, 3):\n",
    "        trigram_model[(w1, w2)][w3] += 1\n",
    "\n",
    "trigram_model[\"<BOS>\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('<BOS>', 'buen'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000001B962BE5620>, {'hombre': 3, 'término': 1, 'seguro': 2, 'deseo': 2, 'talante': 1, 'rostro': 1, 'suceso': 1, 'árbol': 1, 'número': 1, 'espacio': 1, 'pecho': 1, 'ingenio': 1, 'caballero': 1, 'lenguaje': 1, 'entendimiento': 1}))\n",
      "(('buen', 'hombre'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000001B962BE58A0>, {'andad': 1, 'que': 4, '<EOS>': 5, 'id': 1, 'respondió': 1, 'cómo': 1, 'es': 2, 'porque': 1, 'albarda': 1, 'este': 1, 'dice': 1, 'me': 1, 'ese': 1, 'quería': 1, 'deteneos': 1}))\n",
      "(('hombre', 'andad'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000001B962BE5940>, {'con': 1}))\n",
      "(('andad', 'con'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000001B962BE59E0>, {'dios': 6}))\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for entry in itertools.islice(trigram_model.items(), 4):\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY = set([word.lower() for sent in train_data for word in sent])\n",
    "VOCABULARY_SIZE = len(VOCABULARY) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_probabilities(model: defaultdict) -> defaultdict:\n",
    "    result = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for prefix in model:\n",
    "        # Todas las veces que vemos la key seguido de cualquier cosa\n",
    "        total = float(sum(model[prefix].values()))\n",
    "        for next_word in model[prefix]:\n",
    "            # Laplace smothing\n",
    "            # result[prefix][next_word] = (model[prefix][next_word] + 1) / (total + VOCABULARY_SIZE)\n",
    "            # Without smothing\n",
    "            result[prefix][next_word] = model[prefix][next_word] / total\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_probs = calculate_model_probabilities(trigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 0.06666666666666667),\n",
       " ('lo', 0.06296296296296296),\n",
       " ('la', 0.05925925925925926),\n",
       " ('de', 0.04814814814814815),\n",
       " ('una', 0.040740740740740744),\n",
       " ('un', 0.040740740740740744),\n",
       " ('<EOS>', 0.040740740740740744),\n",
       " ('más', 0.025925925925925925),\n",
       " ('tan', 0.025925925925925925),\n",
       " ('menester', 0.025925925925925925),\n",
       " ('caballero', 0.018518518518518517),\n",
       " ('verdad', 0.018518518518518517),\n",
       " ('posible', 0.014814814814814815),\n",
       " ('muy', 0.014814814814814815),\n",
       " ('mi', 0.014814814814814815),\n",
       " ('nuestro', 0.011111111111111112),\n",
       " ('tal', 0.011111111111111112),\n",
       " ('gente', 0.011111111111111112),\n",
       " ('como', 0.011111111111111112),\n",
       " ('ahora', 0.011111111111111112),\n",
       " ('razón', 0.007407407407407408),\n",
       " ('a', 0.007407407407407408),\n",
       " ('poco', 0.007407407407407408),\n",
       " ('grande', 0.007407407407407408),\n",
       " ('gran', 0.007407407407407408),\n",
       " ('tanto', 0.007407407407407408),\n",
       " ('discreto', 0.007407407407407408),\n",
       " ('su', 0.007407407407407408),\n",
       " ('oficio', 0.007407407407407408),\n",
       " ('todo', 0.007407407407407408),\n",
       " ('opinión', 0.007407407407407408),\n",
       " ('bueno', 0.007407407407407408),\n",
       " ('suyo', 0.007407407407407408),\n",
       " ('vuestra', 0.007407407407407408),\n",
       " ('en', 0.007407407407407408),\n",
       " ('ser', 0.007407407407407408),\n",
       " ('gentil', 0.003703703703703704),\n",
       " ('juan', 0.003703703703703704),\n",
       " ('cuando', 0.003703703703703704),\n",
       " ('moza', 0.003703703703703704),\n",
       " ('pura', 0.003703703703703704),\n",
       " ('fama', 0.003703703703703704),\n",
       " ('madre', 0.003703703703703704),\n",
       " ('libre', 0.003703703703703704),\n",
       " ('escudero', 0.003703703703703704),\n",
       " ('valiente', 0.003703703703703704),\n",
       " ('tiene', 0.003703703703703704),\n",
       " ('mejor', 0.003703703703703704),\n",
       " ('este', 0.003703703703703704),\n",
       " ('pesar', 0.003703703703703704),\n",
       " ('algún', 0.003703703703703704),\n",
       " ('buena', 0.003703703703703704),\n",
       " ('así', 0.003703703703703704),\n",
       " ('predicar', 0.003703703703703704),\n",
       " ('digna', 0.003703703703703704),\n",
       " ('dulce', 0.003703703703703704),\n",
       " ('desati', 0.003703703703703704),\n",
       " ('terrible', 0.003703703703703704),\n",
       " ('necesaria', 0.003703703703703704),\n",
       " ('simple', 0.003703703703703704),\n",
       " ('otro', 0.003703703703703704),\n",
       " ('perseguido', 0.003703703703703704),\n",
       " ('tiempo', 0.003703703703703704),\n",
       " ('amado', 0.003703703703703704),\n",
       " ('dama', 0.003703703703703704),\n",
       " ('olla', 0.003703703703703704),\n",
       " ('nuevo', 0.003703703703703704),\n",
       " ('hija', 0.003703703703703704),\n",
       " ('pública', 0.003703703703703704),\n",
       " ('pensar', 0.003703703703703704),\n",
       " ('sutil', 0.003703703703703704),\n",
       " ('lástima', 0.003703703703703704),\n",
       " ('blanco', 0.003703703703703704),\n",
       " ('negro', 0.003703703703703704),\n",
       " ('parte', 0.003703703703703704),\n",
       " ('tarde', 0.003703703703703704),\n",
       " ('escuela', 0.003703703703703704),\n",
       " ('maravilla', 0.003703703703703704),\n",
       " ('algo', 0.003703703703703704),\n",
       " ('lacayo', 0.003703703703703704),\n",
       " ('bastante', 0.003703703703703704),\n",
       " ('si', 0.003703703703703704),\n",
       " ('decir', 0.003703703703703704),\n",
       " ('al', 0.003703703703703704),\n",
       " ('hombre', 0.003703703703703704),\n",
       " ('mucha', 0.003703703703703704),\n",
       " ('deseado', 0.003703703703703704),\n",
       " ('enseñar', 0.003703703703703704),\n",
       " ('por', 0.003703703703703704),\n",
       " ('hora', 0.003703703703703704),\n",
       " ('cierto', 0.003703703703703704),\n",
       " ('abundantísimo', 0.003703703703703704),\n",
       " ('contra', 0.003703703703703704),\n",
       " ('prerrogativa', 0.003703703703703704),\n",
       " ('cristiano', 0.003703703703703704),\n",
       " ('laberinto', 0.003703703703703704),\n",
       " ('que', 0.003703703703703704),\n",
       " ('valentía', 0.003703703703703704),\n",
       " ('y', 0.003703703703703704),\n",
       " ('fuerza', 0.003703703703703704),\n",
       " ('mía', 0.003703703703703704),\n",
       " ('mentirosa', 0.003703703703703704),\n",
       " ('señal', 0.003703703703703704),\n",
       " ('disparate', 0.003703703703703704),\n",
       " ('reina', 0.003703703703703704),\n",
       " ('mala', 0.003703703703703704),\n",
       " ('esta', 0.003703703703703704),\n",
       " ('uno', 0.003703703703703704),\n",
       " ('antiguo', 0.003703703703703704),\n",
       " ('pobre', 0.003703703703703704),\n",
       " ('imposible', 0.003703703703703704),\n",
       " ('gobernador', 0.003703703703703704),\n",
       " ('vuestro', 0.003703703703703704),\n",
       " ('puerto', 0.003703703703703704),\n",
       " ('vencido', 0.003703703703703704),\n",
       " ('recia', 0.003703703703703704),\n",
       " ('verdadero', 0.003703703703703704),\n",
       " ('villano', 0.003703703703703704),\n",
       " ('tuerta', 0.003703703703703704)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict(trigram_probs[\"que\", \"es\"]).items(), key=lambda x: -1 * x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cual', 0.05555555555555555),\n",
       " ('que', 0.040123456790123455),\n",
       " ('ventero', 0.027777777777777776)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_likely_words(\n",
    "    model_probs: defaultdict, context: str, top_count: int = 10\n",
    ") -> list[tuple]:\n",
    "    \"\"\"Dado un contexto obtiene las palabras más probables\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    model_probs: defaultdict\n",
    "        Probabilidades del modelo\n",
    "    context: str\n",
    "        Contexto con el cual calcular las palabras más probables siguientes\n",
    "    top_count: int\n",
    "        Cantidad de palabras más probables. Default 10\n",
    "    \"\"\"\n",
    "    history = tuple(context.split())\n",
    "    return sorted(dict(model_probs[history]).items(), key=lambda prob: -1 * prob[1])[\n",
    "        :top_count\n",
    "    ]\n",
    "\n",
    "\n",
    "get_likely_words(trigram_probs, \"<BOS> el\", top_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mono'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "def get_next_word(words: list) -> str:\n",
    "    # Strategy here\n",
    "    return words[0][0]\n",
    "\n",
    "\n",
    "def get_next_word(words: list) -> str:\n",
    "    return words[randint(0, len(words) - 1)][0]\n",
    "\n",
    "get_next_word(get_likely_words(trigram_probs, \"<BOS> el\", 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS> el más humilde y subieron a ser venturosas <EOS> "
     ]
    }
   ],
   "source": [
    "MAX_TOKENS = 30\n",
    "\n",
    "def generate_text(model: defaultdict, history: str, tokens_count: int) -> None:\n",
    "    next_word = get_next_word(get_likely_words(model, history, top_count=30))\n",
    "    print(next_word, end=\" \")\n",
    "    tokens_count += 1\n",
    "    if tokens_count == MAX_TOKENS or next_word == \"<EOS>\":\n",
    "        return\n",
    "    generate_text(model, history.split()[1] + \" \" + next_word, tokens_count)\n",
    "\n",
    "sentence = \"<BOS> el\"\n",
    "print(sentence, end=\" \")\n",
    "generate_text(trigram_probs, sentence, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sent_prob(model: defaultdict, sentence: str, n: int) -> float:\n",
    "    n_grams = ngrams(sentence, n)\n",
    "    p = 0.0\n",
    "    for gram in n_grams:\n",
    "        if n == 3:\n",
    "            key = (gram[0], gram[1])\n",
    "            value = gram[2]\n",
    "        elif n == 2:\n",
    "            key = gram[0]\n",
    "            value = gram[1]\n",
    "        try:\n",
    "            if model[key][value] == 0:\n",
    "                # Laplace smoothing\n",
    "                p += np.log(1 / VOCABULARY_SIZE)\n",
    "                continue\n",
    "            log_prob = np.log(model[key][value])\n",
    "            # skip inf values\n",
    "            if log_prob == float(\"-inf\"):\n",
    "                continue\n",
    "            p += log_prob\n",
    "        except:\n",
    "            p += 0.0\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS> buen hombre andad con dios a vuestro lugar con vuestro dinero y de aquí <EOS>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-22.21850428505548"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = train_data[0]\n",
    "print(\" \".join(sentence))\n",
    "calculate_sent_prob(trigram_probs, train_data[10], n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.457602378519944"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate perplexity\n",
    "\"\"\"\n",
    "\n",
    "# perplexity is a measure of how well a probability model predicts a sample\n",
    "# we will use test_data to calculate perplexity for a model trained with train_data\n",
    "\n",
    "perplexities = []\n",
    "for sentence in test_data:\n",
    "    log_prob = calculate_sent_prob(trigram_probs, sentence, n=3)\n",
    "    if (log_prob == float('inf')):\n",
    "        print(sentence)\n",
    "        break\n",
    "    if(len(sentence) == 1):\n",
    "        print(sentence)\n",
    "        break\n",
    "    perplexity = -(log_prob / len(sentence) - 1)\n",
    "    perplexities.append(perplexity)\n",
    "\n",
    "test_data[0]\n",
    "\n",
    "total_perplexity = sum(perplexities) / len(perplexities)\n",
    "total_perplexity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
