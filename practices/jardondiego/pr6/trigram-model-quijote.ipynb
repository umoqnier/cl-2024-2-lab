{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Práctica 6\n",
    "### Modelos del lenguaje\n",
    "\n",
    "**Fecha de entrega**  \n",
    "21 de abril de 2024\n",
    "\n",
    "- Crear un par de modelos del lenguaje usando un corpus en español|\n",
    "    - Corpus: El Quijote\n",
    "    - URL: https://www.gutenberg.org/ebooks/2000\n",
    "    - Modelo de n-gramas con n = [2, 3]\n",
    "    - Hold out con test = 30% y train = 70%\n",
    "- Evaluar los modelos y reportar la perplejidad de cada modelo\n",
    "    - Comparar los resultados entre los diferentes modelos del lenguaje (bigramas, trigramas)\n",
    "    - ¿Cual fue el modelo mejor evaluado? ¿Porqué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: click in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Install dependencies\n",
    "\"\"\"\n",
    "\n",
    "%pip install nltk matplotlib numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Download spanish language corpus\n",
    "\n",
    "El Quijote\n",
    "https://www.gutenberg.org/ebooks/2000\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "import string\n",
    "\n",
    "# url = \"https://www.gutenberg.org/ebooks/2000.txt.utf-8\"\n",
    "# response = requests.get(url)\n",
    "\n",
    "# with open('quijote.txt', 'wb') as file:\n",
    "#     file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example sentence:\n",
      "['<BOS>', 'febrero', 'de', 'mil', 'y', 'seiscientos', 'y', 'quince', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Preprocessing\n",
    "\"\"\"\n",
    "\n",
    "with open('quijote.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.readlines()\n",
    "\n",
    "# perform preprocessing\n",
    "\n",
    "# trim lines\n",
    "text = [line.strip() for line in text if line.strip()]\n",
    "\n",
    "# make lowercase\n",
    "text = [line.lower() for line in text]\n",
    "\n",
    "# remove punctuation\n",
    "text = [''.join([c for c in line if c not in string.punctuation]) for line in text]\n",
    "\n",
    "# remove special characters and numbers\n",
    "text = [''.join([c for c in line if c.isalpha() or c == ' ']) for line in text]\n",
    "\n",
    "# add <BOS> and <EOS> tokens\n",
    "text = ['<BOS> ' + line + ' <EOS>' for line in text]\n",
    "\n",
    "# split into words\n",
    "text = [line.split() for line in text]\n",
    "\n",
    "\n",
    "print('example sentence:')\n",
    "print(text[np.random.randint(len(text))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n",
      "['<BOS>', 'no', 'se', 'anduviera', 'hocicando', 'con', 'alguno', 'de', 'los', 'que', 'están', 'en', 'la', 'rueda', 'a', 'vuelta', '<EOS>']\n",
      "Test data:\n",
      "['<BOS>', 'triste', 'armonía', 'especialmente', 'don', 'quijote', 'que', 'no', 'cabía', 'en', 'su', 'asiento', 'de', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split training and test data\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(text, test_size=0.2)\n",
    "\n",
    "# print out a random sample of the training data and the test data\n",
    "print('Training data:')\n",
    "print(train_data[np.random.randint(len(train_data))])\n",
    "print('Test data:')\n",
    "print(test_data[np.random.randint(len(test_data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<BOS>', 'espejos', 'que'),\n",
       " ('espejos', 'que', 'a'),\n",
       " ('que', 'a', 'sus'),\n",
       " ('a', 'sus', 'pies'),\n",
       " ('sus', 'pies', 'tiene'),\n",
       " ('pies', 'tiene', 'porque'),\n",
       " ('tiene', 'porque', 'sin'),\n",
       " ('porque', 'sin', 'duda'),\n",
       " ('sin', 'duda', 'alguna'),\n",
       " ('duda', 'alguna', 'es'),\n",
       " ('alguna', 'es', 'el'),\n",
       " ('es', 'el', 'atrevido'),\n",
       " ('el', 'atrevido', 'y'),\n",
       " ('atrevido', 'y', 'mal'),\n",
       " ('y', 'mal', '<EOS>')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import ngrams\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "list(ngrams(text[np.random.randint(len(text))], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>.<locals>.<lambda>()>, {})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Train tri-gram model using nltk\n",
    "\"\"\"\n",
    "\n",
    "# a trigram model is a dictionary of dictionaries\n",
    "# by default the inner dictionary is a defaultdict with a default value of 0\n",
    "# i.e. if a key is not found in the dictionary, it will return 0\n",
    "# this is useful for counting the number of times a word appears after a bigram\n",
    "trigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "\n",
    "for sentence in train_data:\n",
    "    for w1, w2, w3 in ngrams(sentence, 3):\n",
    "        trigram_model[(w1, w2)][w3] += 1\n",
    "\n",
    "trigram_model[\"<BOS>\", \"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('<BOS>', 'renombre'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000155E10FCF40>, {'de': 1, 'famoso': 1}))\n",
      "(('renombre', 'de'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000155E10FCEA0>, {'loco': 1, '<EOS>': 1, 'magno': 1, 'valiente': 1}))\n",
      "(('de', 'loco'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000155E10FD260>, {'que': 2, 'y': 1, 'a': 1}))\n",
      "(('loco', 'que'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x00000155E10FD3A0>, {'puesto': 1, '<EOS>': 2, 'me': 1, 'de': 1, 'a': 2, 'estaba': 1, 'con': 1, 'por': 1, 'tiraba': 1, 'dio': 1, 'ya': 1}))\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for entry in itertools.islice(trigram_model.items(), 4):\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCABULARY = set([word.lower() for sent in train_data for word in sent])\n",
    "VOCABULARY_SIZE = len(VOCABULARY) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model_probabilities(model: defaultdict) -> defaultdict:\n",
    "    result = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for prefix in model:\n",
    "        # Todas las veces que vemos la key seguido de cualquier cosa\n",
    "        total = float(sum(model[prefix].values()))\n",
    "        for next_word in model[prefix]:\n",
    "            # Laplace smothing\n",
    "            # result[prefix][next_word] = (model[prefix][next_word] + 1) / (total + VOCABULARY_SIZE)\n",
    "            # Without smothing\n",
    "            result[prefix][next_word] = model[prefix][next_word] / total\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_probs = calculate_model_probabilities(trigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('el', 0.07662835249042145),\n",
       " ('lo', 0.05747126436781609),\n",
       " ('la', 0.05363984674329502),\n",
       " ('un', 0.05363984674329502),\n",
       " ('de', 0.04980842911877394),\n",
       " ('<EOS>', 0.04597701149425287),\n",
       " ('una', 0.0421455938697318),\n",
       " ('más', 0.034482758620689655),\n",
       " ('menester', 0.034482758620689655),\n",
       " ('tan', 0.022988505747126436),\n",
       " ('muy', 0.019157088122605363),\n",
       " ('caballero', 0.01532567049808429),\n",
       " ('a', 0.011494252873563218),\n",
       " ('como', 0.011494252873563218),\n",
       " ('tal', 0.011494252873563218),\n",
       " ('ahora', 0.011494252873563218),\n",
       " ('mi', 0.011494252873563218),\n",
       " ('posible', 0.011494252873563218),\n",
       " ('nuestro', 0.011494252873563218),\n",
       " ('razón', 0.011494252873563218),\n",
       " ('opinión', 0.007662835249042145),\n",
       " ('verdad', 0.007662835249042145),\n",
       " ('su', 0.007662835249042145),\n",
       " ('tiempo', 0.007662835249042145),\n",
       " ('uno', 0.007662835249042145),\n",
       " ('todo', 0.007662835249042145),\n",
       " ('mejor', 0.007662835249042145),\n",
       " ('suyo', 0.007662835249042145),\n",
       " ('en', 0.007662835249042145),\n",
       " ('gente', 0.007662835249042145),\n",
       " ('grande', 0.007662835249042145),\n",
       " ('cristiano', 0.0038314176245210726),\n",
       " ('necesaria', 0.0038314176245210726),\n",
       " ('deseosa', 0.0038314176245210726),\n",
       " ('determinación', 0.0038314176245210726),\n",
       " ('escudero', 0.0038314176245210726),\n",
       " ('hombre', 0.0038314176245210726),\n",
       " ('bastante', 0.0038314176245210726),\n",
       " ('cuando', 0.0038314176245210726),\n",
       " ('algo', 0.0038314176245210726),\n",
       " ('maravilla', 0.0038314176245210726),\n",
       " ('abundantísimo', 0.0038314176245210726),\n",
       " ('gran', 0.0038314176245210726),\n",
       " ('imposible', 0.0038314176245210726),\n",
       " ('pobre', 0.0038314176245210726),\n",
       " ('peor', 0.0038314176245210726),\n",
       " ('tarde', 0.0038314176245210726),\n",
       " ('perseguido', 0.0038314176245210726),\n",
       " ('mía', 0.0038314176245210726),\n",
       " ('juan', 0.0038314176245210726),\n",
       " ('pública', 0.0038314176245210726),\n",
       " ('amada', 0.0038314176245210726),\n",
       " ('oficio', 0.0038314176245210726),\n",
       " ('disparate', 0.0038314176245210726),\n",
       " ('bueno', 0.0038314176245210726),\n",
       " ('hija', 0.0038314176245210726),\n",
       " ('verdadero', 0.0038314176245210726),\n",
       " ('dulce', 0.0038314176245210726),\n",
       " ('valiente', 0.0038314176245210726),\n",
       " ('discreto', 0.0038314176245210726),\n",
       " ('mucha', 0.0038314176245210726),\n",
       " ('proveedor', 0.0038314176245210726),\n",
       " ('algún', 0.0038314176245210726),\n",
       " ('vergüenza', 0.0038314176245210726),\n",
       " ('simple', 0.0038314176245210726),\n",
       " ('tuerta', 0.0038314176245210726),\n",
       " ('cierto', 0.0038314176245210726),\n",
       " ('hora', 0.0038314176245210726),\n",
       " ('blanco', 0.0038314176245210726),\n",
       " ('negro', 0.0038314176245210726),\n",
       " ('predicar', 0.0038314176245210726),\n",
       " ('puerto', 0.0038314176245210726),\n",
       " ('señal', 0.0038314176245210726),\n",
       " ('tanto', 0.0038314176245210726),\n",
       " ('parte', 0.0038314176245210726),\n",
       " ('poco', 0.0038314176245210726),\n",
       " ('amado', 0.0038314176245210726),\n",
       " ('decir', 0.0038314176245210726),\n",
       " ('madre', 0.0038314176245210726),\n",
       " ('pura', 0.0038314176245210726),\n",
       " ('gentil', 0.0038314176245210726),\n",
       " ('este', 0.0038314176245210726),\n",
       " ('otro', 0.0038314176245210726),\n",
       " ('prerrogativa', 0.0038314176245210726),\n",
       " ('gobernador', 0.0038314176245210726),\n",
       " ('recia', 0.0038314176245210726),\n",
       " ('laberinto', 0.0038314176245210726),\n",
       " ('dama', 0.0038314176245210726),\n",
       " ('vencido', 0.0038314176245210726),\n",
       " ('cristiana', 0.0038314176245210726),\n",
       " ('respondió', 0.0038314176245210726),\n",
       " ('al', 0.0038314176245210726),\n",
       " ('libre', 0.0038314176245210726),\n",
       " ('vuesa', 0.0038314176245210726),\n",
       " ('mío', 0.0038314176245210726),\n",
       " ('antiguo', 0.0038314176245210726),\n",
       " ('buena', 0.0038314176245210726),\n",
       " ('sutil', 0.0038314176245210726),\n",
       " ('lacayo', 0.0038314176245210726),\n",
       " ('contra', 0.0038314176245210726),\n",
       " ('desati', 0.0038314176245210726),\n",
       " ('por', 0.0038314176245210726),\n",
       " ('nuevo', 0.0038314176245210726),\n",
       " ('valentía', 0.0038314176245210726),\n",
       " ('ser', 0.0038314176245210726),\n",
       " ('mentirosa', 0.0038314176245210726),\n",
       " ('fama', 0.0038314176245210726),\n",
       " ('tanta', 0.0038314176245210726),\n",
       " ('terrible', 0.0038314176245210726),\n",
       " ('enseñar', 0.0038314176245210726),\n",
       " ('esta', 0.0038314176245210726),\n",
       " ('olla', 0.0038314176245210726),\n",
       " ('y', 0.0038314176245210726),\n",
       " ('suplemento', 0.0038314176245210726)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dict(trigram_probs[\"que\", \"es\"]).items(), key=lambda x: -1 * x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cual', 0.05198776758409786),\n",
       " ('duque', 0.03058103975535168),\n",
       " ('que', 0.03058103975535168)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_likely_words(\n",
    "    model_probs: defaultdict, context: str, top_count: int = 10\n",
    ") -> list[tuple]:\n",
    "    \"\"\"Dado un contexto obtiene las palabras más probables\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    model_probs: defaultdict\n",
    "        Probabilidades del modelo\n",
    "    context: str\n",
    "        Contexto con el cual calcular las palabras más probables siguientes\n",
    "    top_count: int\n",
    "        Cantidad de palabras más probables. Default 10\n",
    "    \"\"\"\n",
    "    history = tuple(context.split())\n",
    "    return sorted(dict(model_probs[history]).items(), key=lambda prob: -1 * prob[1])[\n",
    "        :top_count\n",
    "    ]\n",
    "\n",
    "\n",
    "get_likely_words(trigram_probs, \"<BOS> el\", top_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barbero'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "\n",
    "def get_next_word(words: list) -> str:\n",
    "    # Strategy here\n",
    "    return words[0][0]\n",
    "\n",
    "\n",
    "def get_next_word(words: list) -> str:\n",
    "    return words[randint(0, len(words) - 1)][0]\n",
    "\n",
    "get_next_word(get_likely_words(trigram_probs, \"<BOS> el\", 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS> el tiempo a mi linaje noble mis padres la cual lamentable historia <EOS> "
     ]
    }
   ],
   "source": [
    "MAX_TOKENS = 30\n",
    "\n",
    "def generate_text(model: defaultdict, history: str, tokens_count: int) -> None:\n",
    "    next_word = get_next_word(get_likely_words(model, history, top_count=30))\n",
    "    print(next_word, end=\" \")\n",
    "    tokens_count += 1\n",
    "    if tokens_count == MAX_TOKENS or next_word == \"<EOS>\":\n",
    "        return\n",
    "    generate_text(model, history.split()[1] + \" \" + next_word, tokens_count)\n",
    "\n",
    "sentence = \"<BOS> el\"\n",
    "print(sentence, end=\" \")\n",
    "generate_text(trigram_probs, sentence, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sent_prob(model: defaultdict, sentence: str, n: int) -> float:\n",
    "    n_grams = ngrams(sentence, n)\n",
    "    p = 0.0\n",
    "    for gram in n_grams:\n",
    "        if n == 3:\n",
    "            key = (gram[0], gram[1])\n",
    "            value = gram[2]\n",
    "        elif n == 2:\n",
    "            key = gram[0]\n",
    "            value = gram[1]\n",
    "        try:\n",
    "            p += np.log(model[key][value])\n",
    "        except:\n",
    "            p += 0.0\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS> renombre de loco que puesto que lo he sido no querría confirmar esta <EOS>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-23.791575488443925"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = train_data[0]\n",
    "print(\" \".join(sentence))\n",
    "calculate_sent_prob(trigram_probs, train_data[10], n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\diego\\AppData\\Local\\Temp\\ipykernel_7020\\2217215399.py:12: RuntimeWarning: divide by zero encountered in log\n",
      "  p += np.log(model[key][value])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate perplexity\n",
    "\"\"\"\n",
    "\n",
    "# perplexity is a measure of how well a probability model predicts a sample\n",
    "# we will use test_data to calculate perplexity for a model trained with train_data\n",
    "\n",
    "perplexities = []\n",
    "for sentence in test_data:\n",
    "    log_prob = calculate_sent_prob(trigram_probs, sentence, 3)\n",
    "    perplexity = -(log_prob / len(sentence) - 1)\n",
    "    perplexities.append(perplexity)\n",
    "\n",
    "total_perplexity = sum(perplexities) / len(perplexities)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
