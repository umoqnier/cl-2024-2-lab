{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: click in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (4.50.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\diego\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk matplotlib numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\diego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"reuters\")\n",
    "nltk.download(\"punkt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54716"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computando números\n",
    "import numpy as np\n",
    "\n",
    "# Corpus\n",
    "from nltk.corpus import reuters\n",
    "\n",
    "# Para crear ngramas\n",
    "from nltk import ngrams\n",
    "\n",
    "# Utilidades para manejar las probabilidades\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "len(reuters.sents())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'surplus', 'helped', 'swell', 'Taiwan', \"'\", 's', 'foreign', 'exchange', 'reserves', 'to', '53', 'billion', 'dlrs', ',', 'among', 'the', 'world', \"'\", 's', 'largest', '.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ASIAN', 'EXPORTERS', 'FEAR'),\n",
       " ('EXPORTERS', 'FEAR', 'DAMAGE'),\n",
       " ('FEAR', 'DAMAGE', 'FROM'),\n",
       " ('DAMAGE', 'FROM', 'U'),\n",
       " ('FROM', 'U', '.'),\n",
       " ('U', '.', 'S'),\n",
       " ('.', 'S', '.-'),\n",
       " ('S', '.-', 'JAPAN'),\n",
       " ('.-', 'JAPAN', 'RIFT'),\n",
       " ('JAPAN', 'RIFT', 'Mounting'),\n",
       " ('RIFT', 'Mounting', 'trade'),\n",
       " ('Mounting', 'trade', 'friction'),\n",
       " ('trade', 'friction', 'between'),\n",
       " ('friction', 'between', 'the'),\n",
       " ('between', 'the', 'U'),\n",
       " ('the', 'U', '.'),\n",
       " ('U', '.', 'S'),\n",
       " ('.', 'S', '.'),\n",
       " ('S', '.', 'And'),\n",
       " ('.', 'And', 'Japan'),\n",
       " ('And', 'Japan', 'has'),\n",
       " ('Japan', 'has', 'raised'),\n",
       " ('has', 'raised', 'fears'),\n",
       " ('raised', 'fears', 'among'),\n",
       " ('fears', 'among', 'many'),\n",
       " ('among', 'many', 'of'),\n",
       " ('many', 'of', 'Asia'),\n",
       " ('of', 'Asia', \"'\"),\n",
       " ('Asia', \"'\", 's'),\n",
       " (\"'\", 's', 'exporting'),\n",
       " ('s', 'exporting', 'nations'),\n",
       " ('exporting', 'nations', 'that'),\n",
       " ('nations', 'that', 'the'),\n",
       " ('that', 'the', 'row'),\n",
       " ('the', 'row', 'could'),\n",
       " ('row', 'could', 'inflict'),\n",
       " ('could', 'inflict', 'far'),\n",
       " ('inflict', 'far', '-'),\n",
       " ('far', '-', 'reaching'),\n",
       " ('-', 'reaching', 'economic'),\n",
       " ('reaching', 'economic', 'damage'),\n",
       " ('economic', 'damage', ','),\n",
       " ('damage', ',', 'businessmen'),\n",
       " (',', 'businessmen', 'and'),\n",
       " ('businessmen', 'and', 'officials'),\n",
       " ('and', 'officials', 'said'),\n",
       " ('officials', 'said', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def preprocess(sent: list[str]) -> list[str]:\n",
    "    \"\"\"Función de preprocesamiento\n",
    "\n",
    "    Agrega tokens de inicio y fin, normaliza todo a minusculas\n",
    "    \"\"\"\n",
    "    result = [word.lower() for word in sent]\n",
    "    # Al final de la oración\n",
    "    result.append(\"<EOS>\")\n",
    "    result.insert(0, \"<BOS>\")\n",
    "    return result\n",
    "\n",
    "\n",
    "print(reuters.sents()[11])\n",
    "preprocess(reuters.sents()[11])\n",
    "list(ngrams(reuters.sents()[0], 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('<BOS>', 'asian'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000001D8934E1620>, {'exporters': 1, 'cocoa': 1, 'dollar': 2}))\n",
      "(('asian', 'exporters'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000001D8B3AD8860>, {'fear': 1}))\n",
      "(('exporters', 'fear'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000001D8B3AD8900>, {'damage': 1, 'china': 1}))\n",
      "(('fear', 'damage'), defaultdict(<function <lambda>.<locals>.<lambda> at 0x000001D8B3AD87C0>, {'from': 1}))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 0.2328767123287671),\n",
       " ('a', 0.21232876712328766),\n",
       " ('not', 0.0684931506849315),\n",
       " ('about', 0.03424657534246575),\n",
       " ('because', 0.03424657534246575),\n",
       " ('why', 0.02054794520547945),\n",
       " ('an', 0.02054794520547945),\n",
       " ('going', 0.02054794520547945),\n",
       " ('expected', 0.0136986301369863),\n",
       " ('just', 0.0136986301369863),\n",
       " ('hardly', 0.0136986301369863),\n",
       " ('done', 0.0136986301369863),\n",
       " ('in', 0.0136986301369863),\n",
       " ('when', 0.0136986301369863),\n",
       " ('22', 0.00684931506849315),\n",
       " ('believed', 0.00684931506849315),\n",
       " ('partly', 0.00684931506849315),\n",
       " ('strictly', 0.00684931506849315),\n",
       " ('yen', 0.00684931506849315),\n",
       " ('amore', 0.00684931506849315),\n",
       " ('up', 0.00684931506849315),\n",
       " ('well', 0.00684931506849315),\n",
       " ('most', 0.00684931506849315),\n",
       " ('definitely', 0.00684931506849315),\n",
       " ('clearly', 0.00684931506849315),\n",
       " ('approved', 0.00684931506849315),\n",
       " ('making', 0.00684931506849315),\n",
       " ('equivalent', 0.00684931506849315),\n",
       " ('based', 0.00684931506849315),\n",
       " ('reflecting', 0.00684931506849315),\n",
       " ('really', 0.00684931506849315),\n",
       " ('too', 0.00684931506849315),\n",
       " ('underpinning', 0.00684931506849315),\n",
       " ('still', 0.00684931506849315),\n",
       " ('possible', 0.00684931506849315),\n",
       " ('probably', 0.00684931506849315),\n",
       " ('first', 0.00684931506849315),\n",
       " ('700', 0.00684931506849315),\n",
       " ('unlikely', 0.00684931506849315),\n",
       " ('totally', 0.00684931506849315),\n",
       " ('within', 0.00684931506849315),\n",
       " ('what', 0.00684931506849315),\n",
       " ('being', 0.00684931506849315),\n",
       " ('reflected', 0.00684931506849315),\n",
       " ('entirely', 0.00684931506849315),\n",
       " ('very', 0.00684931506849315),\n",
       " ('after', 0.00684931506849315),\n",
       " ('potentially', 0.00684931506849315),\n",
       " ('now', 0.00684931506849315),\n",
       " ('above', 0.00684931506849315),\n",
       " ('congress', 0.00684931506849315),\n",
       " ('certainly', 0.00684931506849315),\n",
       " ('available', 0.00684931506849315),\n",
       " ('also', 0.00684931506849315)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_model = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "N = 3\n",
    "for sentence in reuters.sents():\n",
    "    # Obtenemos los ngramas normalizados\n",
    "    n_grams = ngrams(preprocess(sentence), N)\n",
    "    # Guardamos los bigramas en nuestro diccionario\n",
    "    for w1, w2, w3 in n_grams:\n",
    "        trigram_model[(w1, w2)][w3] += 1\n",
    "\n",
    "trigram_model[\"<BOS>\", \"the\"]\n",
    "\n",
    "for i, entry in enumerate(trigram_model.items()):\n",
    "    print(entry)\n",
    "    if i == 3:\n",
    "        break\n",
    "\n",
    "VOCABULARY = set([word.lower() for sent in reuters.sents() for word in sent])\n",
    "# +2 por los tokens <BOS> y <EOS>\n",
    "VOCABULARY_SIZE = len(VOCABULARY) + 2\n",
    "\n",
    "\n",
    "def calculate_model_probabilities(model: defaultdict) -> defaultdict:\n",
    "    result = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    for prefix in model:\n",
    "        # Todas las veces que vemos la key seguido de cualquier cosa\n",
    "        total = float(sum(model[prefix].values()))\n",
    "        for next_word in model[prefix]:\n",
    "            # Laplace smothing\n",
    "            # result[prefix][next_word] = (model[prefix][next_word] + 1) / (total + VOCABULARY_SIZE)\n",
    "            # Without smothing\n",
    "            result[prefix][next_word] = model[prefix][next_word] / total\n",
    "    return result\n",
    "\n",
    "\n",
    "trigram_probs = calculate_model_probabilities(trigram_model)\n",
    "sorted(dict(trigram_probs[\"this\", \"is\"]).items(), key=lambda x: -1 * x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('company', 0.13028764805414553),\n",
       " ('bank', 0.024591088550479413),\n",
       " ('u', 0.01500282007896221)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_likely_words(\n",
    "    model_probs: defaultdict, context: str, top_count: int = 10\n",
    ") -> list[tuple]:\n",
    "    \"\"\"Dado un contexto obtiene las palabras más probables\n",
    "\n",
    "    Params\n",
    "    ------\n",
    "    model_probs: defaultdict\n",
    "        Probabilidades del modelo\n",
    "    context: str\n",
    "        Contexto con el cual calcular las palabras más probables siguientes\n",
    "    top_count: int\n",
    "        Cantidad de palabras más probables. Default 10\n",
    "    \"\"\"\n",
    "    history = tuple(context.split())\n",
    "    return sorted(dict(model_probs[history]).items(), key=lambda prob: -1 * prob[1])[\n",
    "        :top_count\n",
    "    ]\n",
    "\n",
    "\n",
    "get_likely_words(trigram_probs, \"<BOS> the\", top_count=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
