# -*- coding: utf-8 -*-
"""LevelsOfLanguage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vwup15A--DIdzuEEHqPhiHUie_tED2Tg
"""

# Explorando el corpus
import requests as r

response = r.get("https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/en_US.txt")

from pprint import pprint as pp
ipa_data = response.text.split("\n")
#print(ipa_data[-4:])

def response_to_dict(ipa_list: list) -> dict:
    """Parse to dict the list of word-IPA

    Each element of text have the format:
    [WORD][TAB][IPA]

    Parameters
    ----------
    ipa_list: list
        List with each row of ipa-dict raw dataset file

    Returns
    -------
    dict:
        A dictionary with the word as key and the phonetic
        representation as value
    """
    result = {}
    for item in ipa_list:
       item_list = item.split("\t")
       result[item_list[0]] = item_list[1]
    return result

def get_ipa_dict(iso_lang: str) -> dict:
    """Get ipa-dict file from Github

    Parameters:
    -----------
    iso_lang:
        Language as iso code

    Results:
    --------
    dict:
        Dictionary with words as keys and phonetic representation
        as values for a given lang code
    """
    print(f"Downloading {iso_lang}", end=" ")
    response = r.get(f"https://raw.githubusercontent.com/open-dict-data/ipa-dict/master/data/{iso_lang}.txt")
    raw_data = response.text.split("\n")
    print(f"status:{response.status_code}")
    return response_to_dict(raw_data[:-1])



es_mx_ipa = get_ipa_dict("es_MX")

def query_ipa_transcriptions(word: str, dataset: dict) -> list[str]:
    """Search for a word in an IPA phonetics dict

    Given a word this function return the IPA transcriptions

    Parameters:
    -----------
    word: str
        A word to search in the dataset
    dataset: dict
        A dataset for a given language code

    Returns
    -------
    list[str]:
        List with posible transcriptions if any,
        else a list with the string "NOT FOUND"
    """
    return dataset.get(word.lower(), "NOT FOUND").split(", ")

"""Obtengamos un par de datasets"""

# Get datasets
dataset_mx = get_ipa_dict("es_MX")
dataset_us = get_ipa_dict("en_US")

"""Obteniendo corpora de github"""

lang_codes = {
  "ar": "Arabic (Modern Standard)",
  "de": "German",
  "en_UK": "English (Received Pronunciation)",
  "en_US": "English (General American)",
  "eo": "Esperanto",
  "es_ES": "Spanish (Spain)",
  "es_MX": "Spanish (Mexico)",
  "fa": "Persian",
  "fi": "Finnish",
  "fr_FR": "French (France)",
  "fr_QC": "French (Québec)",
  "is": "Icelandic",
  "ja": "Japanese",
  "jam": "Jamaican Creole",
  "km": "Khmer",
  "ko": "Korean",
  "ma": "Malay (Malaysian and Indonesian)",
  "nb": "Norwegian Bokmål",
  "nl": "Dutch",
  "or": "Odia",
  "ro": "Romanian",
  "sv": "Swedish",
  "sw": "Swahili",
  "tts": "Isan",
  "vi_C": "Vietnamese (Central)",
  "vi_N": "Vietnamese (Northern)",
  "vi_S": "Vietnamese (Southern)",
  "yue": "Cantonese",
  "zh": "Mandarin"
}
iso_lang_codes = list(lang_codes.keys())

def get_dataset() -> dict:
    """Download corpora from ipa-dict github

    Given a list of iso lang codes download available datasets.

    Returns
    -------
    dict
        Lang codes as keys and dictionary with words-transcriptions
        as values
    """
    return {code: get_ipa_dict(code) for code in iso_lang_codes}

dataset = get_dataset()

"""**Aplicaciones**

1.   Búsqueda básica automatizada

  1.1 Buscador de representaciones foneticas de palabras automatizado en diferentes idiomas
"""

print("Representación fonética de palabras")

print("Lenguas disponibles:")
for lang_key in dataset.keys():
    print(f"{lang_key}: {lang_codes[lang_key]}")

lang = input("lang>> ")
print(f"Selected language: {lang_codes[lang]}") if lang else print("Adios 👋🏼")
while lang:
    # El programa comeinza aqui
    sub_data = dataset[lang]
    query = input(f"[{lang}] word>> ")
    results = query_ipa_transcriptions(query, sub_data)
    print(query, " | ", results)
    while query:
        query = input(f"[{lang}] word>> ")
        if query:
            results = query_ipa_transcriptions(query, sub_data)
            print(query, " | ", results)
    lang = input("lang>> ")

"""  1.2 Buscador de representación fonética de oraciones"""

print("Representación fonética de oraciones")

print("Lenguas disponibles:")
for lang_key in dataset.keys():
    print(f"{lang_key}: {lang_codes[lang_key]}")

lang = input("lang>> ")
print(f"Selected language: {lang_codes[lang]}") if lang else print("Adios 👋🏼")
while lang:
    # El programa comeinza aqui
    sub_data = dataset[lang]
    query = input(f"[{lang}] phrase>> ")
    sentence = query.split()
    out_list = []
    # print("Este debe ser el arreglo", sentence)
    for pos in sentence:
      out_list = query_ipa_transcriptions(pos, sub_data)
      print(pos, " | ", out_list)
    while query:
        query = input(f"[{lang}] phrase>> ")
        sentence = query.split()
        out_list = []
        if query:
            for pos in sentence:
              out_list = query_ipa_transcriptions(pos, sub_data)
              print(pos, " | ", out_list)
    lang = input("lang>> ")

"""2.1 Encontrando palabras que tengan una pronunciación similar"""

from collections import defaultdict

#sentence = "There once was a cat that ate a rat and after that sat on a yellow mat"
#sentence = "the cat sat on the mat and looked at the rat."
#sentence = "If you drop the ball it will fall on the doll"
sentence = "cuando juego con fuego siento como brilla la orilla de mi corazón"

#lang = "en_US"
lang = "es_MX"
words = sentence.split(" ")

# Get words and IPA transciptions map
word_ipa_map = {}
for word in words:
    ipa_transcriptions = query_ipa_transcriptions(word.lower(), dataset.get(lang))
    ipa_transcriptions = [_.strip("/") for _ in ipa_transcriptions]
    word_ipa_map.update({word.lower(): ipa_transcriptions})

patterns = defaultdict(list)
for word, ipa_list in word_ipa_map.items():
    for ipa in ipa_list:
        ipa_pattern = ipa[-2:]
        patterns[ipa_pattern].append(word)

for pattern, words in patterns.items():
    if len(set(words)) > 1:
        print(f"{pattern}:: {words}")

""" 2.2 Dada una palabra te muestre sus homofonos"""

def homophones(ipa_rep: list[str], dataset: dict) -> list[str]:
  homophones = []
  for w in dataset:
    if dataset[w] == ipa_rep[0]:
      homophones.append(w)
  return homophones

#sentence = "cuando juego con fuego siento como brilla la orilla de mi corazón"
sentence = "vaya"
words = sentence.split(" ")

lang = input("lang>> ")
while lang:
    sub_data = dataset[lang]
    query = input(f"[{lang}] word>> ")
    ipa_transcriptions = query_ipa_transcriptions(query.lower(), sub_data)
    homofonos = homophones(ipa_transcriptions, sub_data)
    print(f"{ipa_transcriptions}:: {homofonos}")
    #print(homophones(ipa_transcriptions, sub_data))
    while query:
        query = input(f"[{lang}] word>> ")
        if query:
            ipa_transcriptions = query_ipa_transcriptions(query.lower(), sub_data)
            print(homophones(ipa_transcriptions, sub_data))
    lang = input("lang>> ")